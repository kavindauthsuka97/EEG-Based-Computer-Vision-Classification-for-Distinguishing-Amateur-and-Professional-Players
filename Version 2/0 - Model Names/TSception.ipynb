{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ddf80-dde0-493d-8d77-1401cf61ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "# ----------------- TSception (Keras, channels_first) -----------------\n",
    "\n",
    "def tsception_conv_block(x, out_chan, kernel, step, pool, name_prefix=None):\n",
    "    \"\"\"\n",
    "    x      : (B, C_in, H, W)  with data_format='channels_first'\n",
    "    kernel : (kH, kW)\n",
    "    step   : (sH, sW)\n",
    "    pool   : scalar -> AvgPool over (1, pool)\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(\n",
    "        filters=out_chan,\n",
    "        kernel_size=kernel,\n",
    "        strides=step,\n",
    "        padding=\"valid\",\n",
    "        data_format=\"channels_first\",\n",
    "        use_bias=True,\n",
    "        name=None if name_prefix is None else name_prefix + \"_conv\",\n",
    "    )(x)\n",
    "    x = layers.LeakyReLU(name=None if name_prefix is None else name_prefix + \"_lrelu\")(x)\n",
    "    x = layers.AveragePooling2D(\n",
    "        pool_size=(1, pool),\n",
    "        strides=(1, pool),\n",
    "        data_format=\"channels_first\",\n",
    "        name=None if name_prefix is None else name_prefix + \"_avgpool\",\n",
    "    )(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_tsception_keras(\n",
    "    num_classes,\n",
    "    input_size,        # (1, M, T)  -> (freq, channels, time)\n",
    "    sampling_rate,\n",
    "    num_T,             # temporal filters\n",
    "    num_S,             # spatial filters\n",
    "    hidden,            # hidden units in FC\n",
    "    dropout_rate,\n",
    "):\n",
    "    \"\"\"\n",
    "    Keras implementation of TSception.\n",
    "\n",
    "    input_size : (1, M, T)\n",
    "        1 frequency band, M channels, T time points\n",
    "    sampling_rate : Hz\n",
    "    \"\"\"\n",
    "    F, M, T = input_size\n",
    "    assert F == 1, \"TSceptionKeras assumes a single 'freq band' dimension (F=1).\"\n",
    "\n",
    "    # We follow PyTorch: input to network is (B, 1, chan, time) = (B, 1, M, T)\n",
    "    inp = layers.Input(shape=(1, M, T))  # channels_first\n",
    "\n",
    "    inception_window = [0.5, 0.25, 0.125]\n",
    "    base_pool = 8\n",
    "\n",
    "    # ---------- Temporal branches ----------\n",
    "    k1 = int(inception_window[0] * sampling_rate)\n",
    "    k2 = int(inception_window[1] * sampling_rate)\n",
    "    k3 = int(inception_window[2] * sampling_rate)\n",
    "\n",
    "    x = inp\n",
    "\n",
    "    # Tception1,2,3: kernel=(1, k), stride=1, pool=8\n",
    "    t1 = tsception_conv_block(\n",
    "        x, out_chan=num_T, kernel=(1, k1),\n",
    "        step=(1, 1), pool=base_pool, name_prefix=\"T1\"\n",
    "    )\n",
    "    t2 = tsception_conv_block(\n",
    "        x, out_chan=num_T, kernel=(1, k2),\n",
    "        step=(1, 1), pool=base_pool, name_prefix=\"T2\"\n",
    "    )\n",
    "    t3 = tsception_conv_block(\n",
    "        x, out_chan=num_T, kernel=(1, k3),\n",
    "        step=(1, 1), pool=base_pool, name_prefix=\"T3\"\n",
    "    )\n",
    "\n",
    "    # Concatenate along temporal dimension (last axis for channels_first: B,C,H,W -> axis=3)\n",
    "    t_out = layers.Concatenate(axis=3, name=\"T_concat\")([t1, t2, t3])\n",
    "\n",
    "    # BatchNorm over channel axis (axis=1 in channels_first)\n",
    "    t_out = layers.BatchNormalization(axis=1, name=\"BN_t\")(t_out)\n",
    "\n",
    "    # ---------- Spatial branches ----------\n",
    "    # pool for spatial modules: int(base_pool * 0.25)\n",
    "    s_pool = int(base_pool * 0.25)\n",
    "\n",
    "    # Sception1: kernel=(M,1), stride=(1,1)\n",
    "    s1 = tsception_conv_block(\n",
    "        t_out, out_chan=num_S,\n",
    "        kernel=(int(M), 1),\n",
    "        step=(1, 1),\n",
    "        pool=s_pool,\n",
    "        name_prefix=\"S1\"\n",
    "    )\n",
    "\n",
    "    # Sception2: kernel=(M*0.5,1), stride=(M*0.5,1)\n",
    "    half_M = int(M * 0.5)\n",
    "    s2 = tsception_conv_block(\n",
    "        t_out, out_chan=num_S,\n",
    "        kernel=(half_M, 1),\n",
    "        step=(half_M, 1),\n",
    "        pool=s_pool,\n",
    "        name_prefix=\"S2\"\n",
    "    )\n",
    "\n",
    "    # Concatenate along channel-axis (H dimension here): (B, num_S, H, W) -> axis=2\n",
    "    s_out = layers.Concatenate(axis=2, name=\"S_concat\")([s1, s2])\n",
    "\n",
    "    s_out = layers.BatchNormalization(axis=1, name=\"BN_s\")(s_out)\n",
    "\n",
    "    # ---------- Fusion layer ----------\n",
    "    # fusion_layer: kernel=(3,1), stride=1, pool=4\n",
    "    fusion = tsception_conv_block(\n",
    "        s_out, out_chan=num_S,\n",
    "        kernel=(3, 1),\n",
    "        step=(1, 1),\n",
    "        pool=4,\n",
    "        name_prefix=\"fusion\"\n",
    "    )\n",
    "\n",
    "    fusion = layers.BatchNormalization(axis=1, name=\"BN_fusion\")(fusion)\n",
    "\n",
    "    # ---------- Global pooling + FC ----------\n",
    "    # Mean over spatial dims -> (B, num_S)\n",
    "    feat = layers.GlobalAveragePooling2D(data_format=\"channels_first\", name=\"global_avg\")(fusion)\n",
    "\n",
    "    x = layers.Dense(hidden, activation=\"relu\", name=\"fc1\")(feat)\n",
    "    x = layers.Dropout(dropout_rate, name=\"fc1_drop\")(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\", name=\"fc_out\")(x)\n",
    "\n",
    "    model = Model(inp, out, name=\"TSceptionKeras\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------- Helper: reshape (B,M,T,1) -> (B,1,M,T) -----------------\n",
    "\n",
    "def to_tsception_input(X):\n",
    "    \"\"\"\n",
    "    Convert (B, M, T, 1) -> (B, 1, M, T) for TSceptionKeras.\n",
    "    \"\"\"\n",
    "    assert X.ndim == 4 and X.shape[-1] == 1, f\"Expected X (B,M,T,1), got {X.shape}\"\n",
    "    X = np.squeeze(X, axis=-1)        # (B, M, T)\n",
    "    X = np.expand_dims(X, axis=1)     # (B, 1, M, T)\n",
    "    return X.astype(\"float32\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
