{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc60229-0008-491a-8e76-78c1306f0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "# --------- Transformer utilities ---------\n",
    "\n",
    "def transformer_block(x, dim, heads, dim_head, mlp_dim, dropout):\n",
    "    \"\"\"\n",
    "    One Transformer encoder block with:\n",
    "    - PreNorm + Multi-Head Self Attention + residual\n",
    "    - PreNorm + FeedForward MLP + residual\n",
    "\n",
    "    x: (B, tokens, dim)\n",
    "    \"\"\"\n",
    "    # --- Self-attention with PreNorm ---\n",
    "    x_norm1 = layers.LayerNormalization()(x)\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=heads,\n",
    "        key_dim=dim_head,\n",
    "        dropout=dropout,\n",
    "    )(x_norm1, x_norm1)                         # (B, tokens, heads*dim_head)\n",
    "    # Project back to dim (like to_out in PyTorch)\n",
    "    attn = layers.Dense(dim)(attn)\n",
    "    attn = layers.Dropout(dropout)(attn)\n",
    "    x = layers.Add()([x, attn])\n",
    "\n",
    "    # --- Feed-forward with PreNorm ---\n",
    "    x_norm2 = layers.LayerNormalization()(x)\n",
    "    ff = layers.Dense(mlp_dim, activation=\"gelu\")(x_norm2)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    ff = layers.Dense(dim)(ff)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    x = layers.Add()([x, ff])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class AddClassTokenAndPosEmbedding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Adds a learned [CLS] token and positional embeddings.\n",
    "\n",
    "    Input:  (B, num_patches, dim)\n",
    "    Output: (B, num_patches+1, dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_patches, dim, emb_dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.dim = dim\n",
    "        self.dropout = layers.Dropout(emb_dropout)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # pos_embedding: (1, num_patches+1, dim)\n",
    "        self.pos_embedding = self.add_weight(\n",
    "            name=\"pos_embedding\",\n",
    "            shape=(1, self.num_patches + 1, self.dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        # cls_token: (1, 1, dim)\n",
    "        self.cls_token = self.add_weight(\n",
    "            name=\"cls_token\",\n",
    "            shape=(1, 1, self.dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        # x: (B, num_patches, dim)\n",
    "        B = tf.shape(x)[0]\n",
    "        cls_tokens = tf.repeat(self.cls_token, repeats=B, axis=0)   # (B, 1, dim)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)                      # (B, num_patches+1, dim)\n",
    "\n",
    "        # Add positional embedding (broadcast over batch)\n",
    "        x = x + self.pos_embedding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_eeg_vit_keras(\n",
    "    num_chan,\n",
    "    num_time,\n",
    "    num_patches,\n",
    "    num_classes,\n",
    "    dim=32,\n",
    "    depth=4,\n",
    "    heads=16,\n",
    "    mlp_dim=64,\n",
    "    pool=\"cls\",            # 'cls' or 'mean'\n",
    "    dim_head=64,\n",
    "    dropout=0.1,\n",
    "    emb_dropout=0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Keras version of EEGViT.\n",
    "\n",
    "    PyTorch original:\n",
    "      - Input: (B, num_chan, num_time)\n",
    "      - num_patches * patch_len = num_time\n",
    "\n",
    "    Here we use the same input convention: (B, num_chan, num_time).\n",
    "    \"\"\"\n",
    "\n",
    "    assert pool in {\"cls\", \"mean\"}, \"pool must be either 'cls' or 'mean'\"\n",
    "    assert num_time % num_patches == 0, \"num_time must be divisible by num_patches\"\n",
    "\n",
    "    patch_len = num_time // num_patches  # l in original code\n",
    "\n",
    "    # Input: (B, num_chan, num_time)\n",
    "    inp = layers.Input(shape=(num_chan, num_time), name=\"eeg_input\")\n",
    "\n",
    "    # ---- Patch embedding: Rearrange('b c (n l) -> b n (c l)'); then Linear(c*l -> dim) ----\n",
    "    def to_patches(t):\n",
    "        # t: (B, C, T)\n",
    "        B = tf.shape(t)[0]\n",
    "        C = tf.shape(t)[1]\n",
    "        T = tf.shape(t)[2]\n",
    "\n",
    "        # Reshape time axis into (num_patches, patch_len)\n",
    "        t = tf.reshape(t, (B, C, num_patches, patch_len))  # (B, C, n, l)\n",
    "        t = tf.transpose(t, perm=[0, 2, 1, 3])             # (B, n, C, l)\n",
    "        t = tf.reshape(t, (B, num_patches, C * patch_len)) # (B, n, C*l)\n",
    "        return t\n",
    "\n",
    "    x = layers.Lambda(to_patches, name=\"to_patches\")(inp)       # (B, num_patches, C*l)\n",
    "\n",
    "    x = layers.Dense(dim, name=\"patch_linear\")(x)               # (B, num_patches, dim)\n",
    "\n",
    "    # ---- Add [CLS] token + positional embedding + dropout ----\n",
    "    x = AddClassTokenAndPosEmbedding(\n",
    "        num_patches=num_patches,\n",
    "        dim=dim,\n",
    "        emb_dropout=emb_dropout,\n",
    "        name=\"cls_pos_embedding\"\n",
    "    )(x)                                                        # (B, num_patches+1, dim)\n",
    "\n",
    "    # ---- Transformer encoder stack ----\n",
    "    for i in range(depth):\n",
    "        x = transformer_block(\n",
    "            x,\n",
    "            dim=dim,\n",
    "            heads=heads,\n",
    "            dim_head=dim_head,\n",
    "            mlp_dim=mlp_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    # ---- Pooling: CLS token or mean ----\n",
    "    if pool == \"mean\":\n",
    "        x = tf.reduce_mean(x, axis=1)         # (B, dim)\n",
    "    else:\n",
    "        x = x[:, 0, :]                        # (B, dim)  CLS token\n",
    "\n",
    "    # ---- Final MLP head ----\n",
    "    x = layers.LayerNormalization(name=\"final_norm\")(x)\n",
    "    logits = layers.Dense(num_classes, name=\"logits\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=logits, name=\"EEGViT\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_eeg_vit(model, num_classes=2, lr=1e-3):\n",
    "    \"\"\"Helper to compile like your other models.\"\"\"\n",
    "    if num_classes > 1:\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    "    else:\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        metrics = [tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
