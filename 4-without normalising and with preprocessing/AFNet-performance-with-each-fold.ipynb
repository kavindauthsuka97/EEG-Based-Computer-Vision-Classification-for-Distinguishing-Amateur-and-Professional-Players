{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761d6c52-f9a3-4fe2-8471-13d39f75c17b",
   "metadata": {},
   "source": [
    "step 1- Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa687e6b-af12-41bc-a891-87957c0e2baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# ===== Imports, seeds, and GPU setup =====\n",
    "\n",
    "# Standard libraries\n",
    "import os, random                              # OS utilities and reproducibility helpers\n",
    "import numpy as np                             # Numerical arrays\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf                        # Main DL framework\n",
    "\n",
    "# Keras layers & utilities\n",
    "from tensorflow.keras.layers import (Input, SeparableConv2D, DepthwiseConv2D, BatchNormalization,\n",
    "                                     Activation, AveragePooling2D, Dropout, Dense, Add, Lambda,\n",
    "                                     GlobalAveragePooling2D, GlobalAveragePooling1D,\n",
    "                                     MultiHeadAttention, Reshape, LayerNormalization, Conv2D)\n",
    "from tensorflow.keras.models import Model      # Functional model API\n",
    "from tensorflow.keras.optimizers import Adam   # Optimizer\n",
    "from tensorflow.keras.losses import BinaryCrossentropy  # Binary classification loss\n",
    "from tensorflow.keras.metrics import Accuracy  # Accuracy metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # Training callbacks\n",
    "from tensorflow.keras import backend as K      # Keras backend for static shape queries\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import StratifiedKFold                  # Stratified 5-fold CV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score  # Metrics\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt               # For charts\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42                                     # Fixed seed\n",
    "np.random.seed(SEED)                          # Seed NumPy\n",
    "tf.random.set_seed(SEED)                      # Seed TensorFlow\n",
    "random.seed(SEED)                             # Seed Python\n",
    "\n",
    "# Optional: make TensorFlow more gentle with GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU') # Detect GPUs\n",
    "print(\"TensorFlow:\", tf.__version__)          # Show TF version\n",
    "print(\"GPUs:\", gpus)                          # Show detected GPUs\n",
    "if gpus:                                      # If GPU(s) are present\n",
    "    for g in gpus:                            # Iterate each GPU\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(g, True)  # Enable memory growth\n",
    "        except Exception as e:\n",
    "            print(\"GPU memory growth not set:\", e)             # Warn if not possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b3e49-672e-43a3-8252-a7a9e1d39514",
   "metadata": {},
   "source": [
    "Step 2- Load arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "648f695b-c7be-4fee-9266-cc6c3a6ec304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "Loaded.\n",
      "Raw X shape: (4770, 14, 200) | dtype: float64\n",
      "Raw y shape: (4770,) | dtype: int64\n",
      "y squeezed shape: (4770,) | unique labels: [0 1]\n",
      "X after adding channel dim: (4770, 14, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 1: Load the arrays in the given path (no normalization) =====\n",
    "\n",
    "# Exact Windows paths you provided (raw strings to avoid backslash escapes)\n",
    "eeg_path    = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_pp.npy\"\n",
    "labels_path = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_labels.npy\"\n",
    "\n",
    "print(\"Loading EEG data...\")                 # Status print\n",
    "X = np.load(eeg_path)                        # Load EEG data, expected shape (N, 14, 200)\n",
    "y = np.load(labels_path)                     # Load labels, expected shape (N,) or (N,1)\n",
    "print(\"Loaded.\")                             # Confirm loaded\n",
    "\n",
    "print(\"Raw X shape:\", X.shape, \"| dtype:\", X.dtype)  # Inspect EEG tensor\n",
    "print(\"Raw y shape:\", y.shape, \"| dtype:\", y.dtype)  # Inspect labels\n",
    "\n",
    "y = np.squeeze(y).astype(int)                # Ensure labels are 1D int array\n",
    "print(\"y squeezed shape:\", y.shape, \"| unique labels:\", np.unique(y))  # Show label distribution\n",
    "\n",
    "# Sanity checks on shapes and labels\n",
    "assert X.ndim == 3, f\"Expected X to be (N,14,200). Got {X.shape}\"      # Check rank\n",
    "assert X.shape[1] == 14 and X.shape[2] == 200, \"Expected 14 electrodes and 200 samples per segment.\"  # Check dims\n",
    "assert set(np.unique(y)).issubset({0,1}), \"Labels must be {0,1}.\"      # Binary check\n",
    "\n",
    "# Add channel dimension for Keras Conv2D: (N, 14, 200, 1)\n",
    "X = X[..., np.newaxis]                         # Append channel dim\n",
    "print(\"X after adding channel dim:\", X.shape)  # Verify final input shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c880d4f-929c-4d2d-977c-f59bbb3604bb",
   "metadata": {},
   "source": [
    "Step 3 : Prepare 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9d05c0-3a44-4356-8d75-8ba6da0ceee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared StratifiedKFold with 5 splits.\n",
      "Total samples: 4770\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 2: Prepare the data to perform 5-fold cross validation =====\n",
    "\n",
    "N_SPLITS = 5                                   # Number of CV folds\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS,       # Stratified (preserves class ratios)\n",
    "                      shuffle=True,            # Shuffle before splitting\n",
    "                      random_state=SEED)       # Reproducible splits\n",
    "\n",
    "print(f\"Prepared StratifiedKFold with {N_SPLITS} splits.\")  # Status\n",
    "print(\"Total samples:\", X.shape[0])                         # Dataset size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d287e-c568-426c-aa67-9052f0afe513",
   "metadata": {},
   "source": [
    "Step 4 : Define AFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf73bbb-e758-4d39-a6ec-16c4c19e8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 3: Define AFNet (your code, only shape edits + Keras-safe ops) =====\n",
    "\n",
    "def SpatialAttention(x):\n",
    "    \"\"\"Spatial attention to weight electrodes; uses Keras Reshape/Multiply (no raw tf ops on KerasTensors).\"\"\"\n",
    "    num_electrodes = K.int_shape(x)[1]                        # Static electrode count (14)\n",
    "    attn = GlobalAveragePooling2D()(x)                        # Global pool -> (batch, channels)\n",
    "    attn = Dense(64, activation='relu')(attn)                 # Dense to learn attention features\n",
    "    attn = Dense(num_electrodes, activation='sigmoid')(attn)  # One weight per electrode\n",
    "    attn = Reshape((num_electrodes, 1, 1))(attn)              # Reshape for broadcast across time & channels\n",
    "    x = tf.keras.layers.Multiply()([x, attn])                 # Apply attention weights\n",
    "    return x                                                  # Return attended feature maps\n",
    "\n",
    "def TransformerBlock(x, num_heads=4, key_dim=64, ff_dim=128, dropout_rate=0.1):\n",
    "    \"\"\"Transformer encoder block: MHA + FFN with residuals and layer norms.\"\"\"\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)  # Self-attention\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)                               # Dropout\n",
    "    x = Add()([x, attn_output])                                                   # Residual\n",
    "    x = LayerNormalization()(x)                                                   # LayerNorm\n",
    "\n",
    "    ff = Dense(ff_dim, activation='relu')(x)                                      # Feed-forward (expand)\n",
    "    ff = Dropout(dropout_rate)(ff)                                                # Dropout\n",
    "    ff = Dense(x.shape[-1])(ff)                                                   # Project back\n",
    "    x = Add()([x, ff])                                                            # Residual\n",
    "    x = LayerNormalization()(x)                                                   # LayerNorm\n",
    "    return x                                                                      # Return block output\n",
    "\n",
    "def EEGNet_SpatialTransformer(input_shape=(14, 200, 1), dropout_rate=0.5, num_heads=4, ff_dim=128):\n",
    "    \"\"\"AFNet adapted for (14,200,1); keeps your structure, minimal shape handling for residual add.\"\"\"\n",
    "    print(\"Building model with input_shape:\", input_shape)                         # Trace\n",
    "\n",
    "    inputs = Input(shape=input_shape)                                              # Input tensor\n",
    "\n",
    "    # Depthwise Separable Convolution (temporal)\n",
    "    x = SeparableConv2D(32, (1, 5), padding='same', use_bias=False)(inputs)       # First sep conv\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After sepconv1:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Spatial Attention\n",
    "    x = SpatialAttention(x)                                                        # Attention over electrodes\n",
    "    print(\"After SpatialAttention:\", x.shape)                                      # Shape trace\n",
    "\n",
    "    # Depthwise Spatial Convolution across electrodes (change 61->14)\n",
    "    x = DepthwiseConv2D((14, 1), use_bias=False, depth_multiplier=2, padding='valid')(x)  # Collapse electrode dim\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After depthwise spatial:\", x.shape)                                     # Shape trace (electrode dim -> 1)\n",
    "\n",
    "    # Residual branch from inputs via the same first sepconv path (to get 32 channels & same HxW)\n",
    "    res = SeparableConv2D(32, (1, 5), padding='same', use_bias=False)(inputs)      # Residual features (14x200x32)\n",
    "    res = BatchNormalization()(res)                                                # BN\n",
    "    res = Activation('relu')(res)                                                  # ReLU\n",
    "    print(\"Residual branch shape:\", res.shape)                                     # Shape trace\n",
    "\n",
    "    # Project x back to 32 channels so we can add with residual\n",
    "    x = Conv2D(32, (1,1), padding='same', use_bias=False)(x)                       # 1x1 to 32 channels\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After 1x1 proj to 32:\", x.shape)                                        # Shape trace (1x200x32)\n",
    "\n",
    "    # Tile the electrode axis from 1 -> 14 to match residual spatial dims for Add()\n",
    "    x = Lambda(lambda t: tf.repeat(t, repeats=input_shape[0], axis=1))(x)          # Repeat along axis=1\n",
    "    print(\"After tiling to electrodes=14:\", x.shape)                                # Shape trace (14x200x32)\n",
    "\n",
    "    # Add residual and continue\n",
    "    x = Add()([x, res])                                                            # Residual add\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    print(\"After residual add:\", x.shape)                                          # Shape trace\n",
    "\n",
    "    # First Average Pooling (temporal downsampling: 200 -> 50)\n",
    "    x = AveragePooling2D((1, 4))(x)                                                # Pool time axis\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    print(\"After avgpool1:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Second separable conv block\n",
    "    x = SeparableConv2D(64, (1, 3), padding='same', use_bias=False)(x)             # More features\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After sepconv2:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Second Average Pooling (temporal downsampling: ~50 -> ~12/13)\n",
    "    x = AveragePooling2D((1, 4))(x)                                                # Pool time again\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    print(\"After avgpool2:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Transformer over electrodes (tokens = 14, features = T' * 64)\n",
    "    x_shape = K.int_shape(x)                                                       # Static shape\n",
    "    seq_len = x_shape[1]                                                           # Electrode tokens (14)\n",
    "    feat_dim = x_shape[2] * x_shape[3]                                             # Feature dim per token\n",
    "    x = Reshape((seq_len, feat_dim))(x)                                            # (batch, 14, T'*64)\n",
    "    print(\"Before Transformer, reshaped to:\", x.shape)                              # Trace shape\n",
    "\n",
    "    x = TransformerBlock(x, num_heads=num_heads, key_dim=64, ff_dim=ff_dim, dropout_rate=0.1)  # Transformer\n",
    "\n",
    "    # Classifier head\n",
    "    x = GlobalAveragePooling1D()(x)                                                # Pool across tokens\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    print(\"After GAP1D:\", x.shape)                                                 # Shape trace\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)                                           # Dense layer\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    outputs = Dense(1, activation='sigmoid')(x)                                    # Sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs, outputs)                                                 # Build model\n",
    "    return model                                                                   # Return uncompiled model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea4ff7da-7351-4e64-8f20-63b7a2caf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Helper: compile model and set up callbacks (Option A: save best .h5 per fold) =====\n",
    "\n",
    "def compile_model():\n",
    "    \"\"\"Create and compile a fresh AFNet model instance.\"\"\"\n",
    "    model = EEGNet_SpatialTransformer(input_shape=(14, 200, 1))             # Build with correct input shape\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),                       # Adam optimizer (lr=1e-3)\n",
    "                  loss=BinaryCrossentropy(),                                # Binary cross-entropy loss\n",
    "                  metrics=[Accuracy()])                                     # Track Accuracy metric\n",
    "    print(model.summary(line_length=120))                                   # Print model summary\n",
    "    return model                                                            # Return compiled model\n",
    "\n",
    "def make_callbacks(fold_idx):\n",
    "    \"\"\"Construct callbacks for a given fold: EarlyStopping + ReduceLROnPlateau + ModelCheckpoint(.h5).\"\"\"\n",
    "    print(f\"Setting up callbacks for fold {fold_idx}...\")                   # Status print\n",
    "\n",
    "    es = EarlyStopping(                                                     # Early stopping\n",
    "        monitor='val_loss',                                                 # Monitor validation loss\n",
    "        patience=15,                                                         # Wait 8 epochs without improvement\n",
    "        restore_best_weights=True,                                          # Restore best weights\n",
    "        verbose=1                                                           # Verbose messages\n",
    "    )\n",
    "\n",
    "    rlrop = ReduceLROnPlateau(                                              # Reduce LR on plateau\n",
    "        monitor='val_loss',                                                 # Monitor validation loss\n",
    "        factor=0.5,                                                         # Halve the LR\n",
    "        patience=4,                                                         # After 4 stagnant epochs\n",
    "        min_lr=1e-6,                                                        # Do not go below 1e-6\n",
    "        verbose=1                                                           # Verbose messages\n",
    "    )\n",
    "\n",
    "    ckpt_path = f\"best_fold_{fold_idx}.h5\"                                  # Save best model as .h5 (HDF5)\n",
    "    ckpt = ModelCheckpoint(                                                 # Checkpoint callback\n",
    "        filepath=ckpt_path,                                                 # Output file path\n",
    "        monitor='val_loss',                                                 # Select best by val_loss\n",
    "        save_best_only=True,                                                # Only save when improved\n",
    "        verbose=1                                                           # Verbose messages\n",
    "        # Note: .h5 requires h5py installed; if missing, run: pip install h5py\n",
    "    )\n",
    "\n",
    "    return [es, rlrop, ckpt]                                                # Return callback list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf0121f8-70fd-4f2c-888d-97e2b3f577a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Fold 1 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_48            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_6\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_49            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_51            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_52            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_12              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_53            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_13              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_6            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│                                   │                              │                   │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_54            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_6\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_55            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_48            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_48[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_6\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_12 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_6 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_49            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_31 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_49[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_51            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_33 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_51[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_32 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_50[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_18 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_52            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_12              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_52[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_53            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_34 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_53[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_13              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_13 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_6            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_6[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_19 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_12[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_12[\u001b[38;5;34m0\u001b[0m][\n",
       "│                                   │                              │                   │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_13[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_54            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_6\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_54[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_55            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_55[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 1...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 5.72299, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 41s - 344ms/step - accuracy: 0.0000e+00 - loss: 0.3576 - val_accuracy: 0.0000e+00 - val_loss: 5.7230 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 5.72299 to 3.92769, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 204ms/step - accuracy: 2.6205e-04 - loss: 0.0895 - val_accuracy: 0.0000e+00 - val_loss: 3.9277 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 3.92769 to 1.57019, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 193ms/step - accuracy: 0.0024 - loss: 0.0488 - val_accuracy: 0.0000e+00 - val_loss: 1.5702 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 1.57019 to 0.35687, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 173ms/step - accuracy: 0.0058 - loss: 0.0755 - val_accuracy: 0.0000e+00 - val_loss: 0.3569 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.35687 to 0.02684, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0107 - loss: 0.0401 - val_accuracy: 0.0084 - val_loss: 0.0268 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.02684\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0042 - loss: 0.0510 - val_accuracy: 0.0566 - val_loss: 0.0493 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.02684\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0055 - loss: 0.0350 - val_accuracy: 0.0168 - val_loss: 0.0686 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.02684\n",
      "120/120 - 21s - 172ms/step - accuracy: 0.0102 - loss: 0.0376 - val_accuracy: 0.0891 - val_loss: 0.2403 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.02684\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0071 - loss: 0.0218 - val_accuracy: 0.1562 - val_loss: 0.0561 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.02684\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0045 - loss: 0.0216 - val_accuracy: 0.0220 - val_loss: 0.0989 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.02684 to 0.01240, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0092 - loss: 0.0139 - val_accuracy: 0.0891 - val_loss: 0.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01240\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0113 - loss: 0.0078 - val_accuracy: 0.1279 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.01240\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0102 - loss: 0.0076 - val_accuracy: 0.1583 - val_loss: 0.0162 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01240\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0155 - loss: 0.0057 - val_accuracy: 0.0922 - val_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01240\n",
      "120/120 - 23s - 189ms/step - accuracy: 0.0189 - loss: 0.0084 - val_accuracy: 0.1237 - val_loss: 0.0209 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.01240 to 0.00425, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 195ms/step - accuracy: 0.0157 - loss: 0.0087 - val_accuracy: 0.1918 - val_loss: 0.0043 - learning_rate: 2.5000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.00425 to 0.00328, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 189ms/step - accuracy: 0.0183 - loss: 0.0023 - val_accuracy: 0.1321 - val_loss: 0.0033 - learning_rate: 2.5000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.00328 to 0.00187, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 24s - 198ms/step - accuracy: 0.0212 - loss: 0.0033 - val_accuracy: 0.1331 - val_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00187\n",
      "120/120 - 23s - 192ms/step - accuracy: 0.0194 - loss: 0.0023 - val_accuracy: 0.1688 - val_loss: 0.0071 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00187\n",
      "120/120 - 23s - 192ms/step - accuracy: 0.0246 - loss: 0.0018 - val_accuracy: 0.1740 - val_loss: 0.0047 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00187\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0241 - loss: 0.0023 - val_accuracy: 0.1667 - val_loss: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00187\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0231 - loss: 0.0045 - val_accuracy: 0.1080 - val_loss: 0.0150 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00187 to 0.00069, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 181ms/step - accuracy: 0.0204 - loss: 0.0020 - val_accuracy: 0.1048 - val_loss: 6.9322e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0257 - loss: 0.0019 - val_accuracy: 0.0713 - val_loss: 0.0031 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00069\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0202 - loss: 0.0016 - val_accuracy: 0.1038 - val_loss: 0.0081 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0265 - loss: 9.6806e-04 - val_accuracy: 0.0786 - val_loss: 0.0053 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0299 - loss: 0.0011 - val_accuracy: 0.0608 - val_loss: 0.0022 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00069\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0288 - loss: 0.0018 - val_accuracy: 0.0577 - val_loss: 0.0060 - learning_rate: 6.2500e-05\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0252 - loss: 0.0011 - val_accuracy: 0.0692 - val_loss: 0.0025 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0259 - loss: 6.6989e-04 - val_accuracy: 0.0755 - val_loss: 0.0026 - learning_rate: 6.2500e-05\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0338 - loss: 5.4922e-04 - val_accuracy: 0.0702 - val_loss: 0.0025 - learning_rate: 6.2500e-05\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0338 - loss: 8.2080e-04 - val_accuracy: 0.0702 - val_loss: 0.0017 - learning_rate: 3.1250e-05\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0309 - loss: 6.8609e-04 - val_accuracy: 0.0597 - val_loss: 0.0020 - learning_rate: 3.1250e-05\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0325 - loss: 8.8541e-04 - val_accuracy: 0.0818 - val_loss: 0.0023 - learning_rate: 3.1250e-05\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0375 - loss: 9.3274e-04 - val_accuracy: 0.0734 - val_loss: 0.0020 - learning_rate: 3.1250e-05\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0359 - loss: 5.4253e-04 - val_accuracy: 0.0671 - val_loss: 0.0020 - learning_rate: 1.5625e-05\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0307 - loss: 8.8237e-04 - val_accuracy: 0.0660 - val_loss: 0.0017 - learning_rate: 1.5625e-05\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00069\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0328 - loss: 7.0256e-04 - val_accuracy: 0.0650 - val_loss: 0.0018 - learning_rate: 1.5625e-05\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "\n",
      "Fold 1 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[477   0]\n",
      " [  0 477]]\n",
      "TN=477, FP=0, FN=0, TP=477\n",
      "\n",
      "Fold 1 Metrics (threshold=0.5):\n",
      "Accuracy    : 1.0000\n",
      "Precision   : 1.0000  (class 1: Professional)\n",
      "Sensitivity : 1.0000     (Recall for class 1)\n",
      "Specificity : 1.0000 (for class 0: Amateur)\n",
      "F1-score    : 1.0000\n",
      "\n",
      "==========================================================================================\n",
      "Fold 2 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_56            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_7\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_57            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_59            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_58            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_60            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_14              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_61            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_15              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_7            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│                                   │                              │                   │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_62            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_7\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_63            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_56            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_35 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_56[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_7\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_14 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_7 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_57            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_36 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_57[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_59            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_38 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_59[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_58            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_58[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_21 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_60            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_14              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_60[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_61            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_39 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_61[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_15              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_15 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_7            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_7[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_22 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_23 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m][\n",
       "│                                   │                              │                   │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_15[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_62            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_7\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_62[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_63            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_63[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 2...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.14904, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 28s - 232ms/step - accuracy: 7.8616e-04 - loss: 0.3387 - val_accuracy: 0.0000e+00 - val_loss: 3.1490 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss did not improve from 3.14904\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0052 - loss: 0.1075 - val_accuracy: 0.0010 - val_loss: 4.6895 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 3.14904 to 2.08747, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0045 - loss: 0.0611 - val_accuracy: 0.0723 - val_loss: 2.0875 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss did not improve from 2.08747\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0068 - loss: 0.0444 - val_accuracy: 0.4287 - val_loss: 2.5110 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 2.08747 to 0.31188, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 0.0068 - loss: 0.0405 - val_accuracy: 0.2275 - val_loss: 0.3119 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.31188 to 0.02178, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 0.0052 - loss: 0.0342 - val_accuracy: 0.2757 - val_loss: 0.0218 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.02178 to 0.01001, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0060 - loss: 0.0310 - val_accuracy: 0.0807 - val_loss: 0.0100 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01001\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0058 - loss: 0.0219 - val_accuracy: 0.1331 - val_loss: 0.0809 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01001\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0073 - loss: 0.0236 - val_accuracy: 0.0304 - val_loss: 0.0387 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01001\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0126 - loss: 0.0249 - val_accuracy: 0.1845 - val_loss: 0.0332 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01001\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0128 - loss: 0.0091 - val_accuracy: 0.3648 - val_loss: 0.0220 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.01001 to 0.00649, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 0.0123 - loss: 0.0080 - val_accuracy: 0.1887 - val_loss: 0.0065 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00649 to 0.00631, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 176ms/step - accuracy: 0.0115 - loss: 0.0062 - val_accuracy: 0.1572 - val_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0157 - loss: 0.0048 - val_accuracy: 0.0776 - val_loss: 0.0139 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0183 - loss: 0.0050 - val_accuracy: 0.0472 - val_loss: 0.0171 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0186 - loss: 0.0045 - val_accuracy: 0.0052 - val_loss: 0.0341 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0210 - loss: 0.0018 - val_accuracy: 0.0556 - val_loss: 0.0210 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0181 - loss: 0.0056 - val_accuracy: 0.0660 - val_loss: 0.0152 - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0207 - loss: 0.0016 - val_accuracy: 0.0587 - val_loss: 0.0217 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0246 - loss: 0.0022 - val_accuracy: 0.0723 - val_loss: 0.0119 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0267 - loss: 0.0041 - val_accuracy: 0.1205 - val_loss: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0207 - loss: 0.0027 - val_accuracy: 0.0524 - val_loss: 0.0095 - learning_rate: 1.2500e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0212 - loss: 0.0018 - val_accuracy: 0.0629 - val_loss: 0.0173 - learning_rate: 1.2500e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0265 - loss: 9.6469e-04 - val_accuracy: 0.0639 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0265 - loss: 5.8590e-04 - val_accuracy: 0.0566 - val_loss: 0.0120 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0244 - loss: 7.4924e-04 - val_accuracy: 0.0377 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0225 - loss: 8.1386e-04 - val_accuracy: 0.0314 - val_loss: 0.0095 - learning_rate: 6.2500e-05\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00631\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0257 - loss: 7.2145e-04 - val_accuracy: 0.0377 - val_loss: 0.0116 - learning_rate: 6.2500e-05\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "\n",
      "Fold 2 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[477   0]\n",
      " [  1 476]]\n",
      "TN=477, FP=0, FN=1, TP=476\n",
      "\n",
      "Fold 2 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9990\n",
      "Precision   : 1.0000  (class 1: Professional)\n",
      "Sensitivity : 0.9979     (Recall for class 1)\n",
      "Specificity : 1.0000 (for class 0: Amateur)\n",
      "F1-score    : 0.9990\n",
      "\n",
      "==========================================================================================\n",
      "Fold 3 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_64            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_8\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_65            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_67            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_25               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_66            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_68            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_16              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_26               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_69            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_17              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_8            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│                                   │                              │                   │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_70            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_8\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_71            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_64            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_40 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_64[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_8\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_16 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_8 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_65            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_41 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_65[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_67            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_25               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_43 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_67[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_66            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_8 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_42 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_66[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_24 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_68            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_16              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_68[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_26               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_69            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_44 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_69[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_17              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_17 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_8            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_8[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_25 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_16[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_26 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_16[\u001b[38;5;34m0\u001b[0m][\n",
       "│                                   │                              │                   │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_17[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_70            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_8\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_70[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_71            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_71[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 3...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 1.70080, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 240ms/step - accuracy: 0.0000e+00 - loss: 0.3009 - val_accuracy: 0.0000e+00 - val_loss: 1.7008 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 1.70080 to 0.43967, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0016 - loss: 0.0842 - val_accuracy: 0.0000e+00 - val_loss: 0.4397 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.43967 to 0.09874, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0013 - loss: 0.0585 - val_accuracy: 0.0000e+00 - val_loss: 0.0987 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.09874\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0058 - loss: 0.0672 - val_accuracy: 0.0000e+00 - val_loss: 0.1036 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.09874 to 0.01852, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0047 - loss: 0.0523 - val_accuracy: 0.0000e+00 - val_loss: 0.0185 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.01852\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0063 - loss: 0.0440 - val_accuracy: 0.0115 - val_loss: 0.0244 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.01852\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0126 - loss: 0.0342 - val_accuracy: 0.0210 - val_loss: 0.0285 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01852\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0176 - loss: 0.0323 - val_accuracy: 0.0755 - val_loss: 0.0220 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01852\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0110 - loss: 0.0293 - val_accuracy: 0.1216 - val_loss: 0.0336 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01852\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0121 - loss: 0.0273 - val_accuracy: 0.0147 - val_loss: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.01852 to 0.01598, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0102 - loss: 0.0145 - val_accuracy: 0.0964 - val_loss: 0.0160 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.01598 to 0.00996, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0147 - loss: 0.0119 - val_accuracy: 0.1656 - val_loss: 0.0100 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00996 to 0.00626, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0178 - loss: 0.0116 - val_accuracy: 0.0660 - val_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00626\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0197 - loss: 0.0120 - val_accuracy: 0.0985 - val_loss: 0.0126 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00626\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0212 - loss: 0.0082 - val_accuracy: 0.2159 - val_loss: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00626\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0191 - loss: 0.0067 - val_accuracy: 0.3082 - val_loss: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.00626 to 0.00611, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0254 - loss: 0.0099 - val_accuracy: 0.1551 - val_loss: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0320 - loss: 0.0095 - val_accuracy: 0.2138 - val_loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00611\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0278 - loss: 0.0108 - val_accuracy: 0.0660 - val_loss: 0.0173 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0325 - loss: 0.0041 - val_accuracy: 0.2642 - val_loss: 0.0122 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0409 - loss: 0.0076 - val_accuracy: 0.3323 - val_loss: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0472 - loss: 0.0029 - val_accuracy: 0.3249 - val_loss: 0.0295 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0532 - loss: 0.0049 - val_accuracy: 0.2547 - val_loss: 0.0270 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0490 - loss: 0.0049 - val_accuracy: 0.2945 - val_loss: 0.0198 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0532 - loss: 0.0030 - val_accuracy: 0.2191 - val_loss: 0.0305 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0545 - loss: 0.0020 - val_accuracy: 0.3187 - val_loss: 0.0166 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0577 - loss: 0.0018 - val_accuracy: 0.3082 - val_loss: 0.0171 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0603 - loss: 0.0011 - val_accuracy: 0.3071 - val_loss: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0653 - loss: 0.0014 - val_accuracy: 0.3082 - val_loss: 0.0193 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0624 - loss: 0.0013 - val_accuracy: 0.2788 - val_loss: 0.0231 - learning_rate: 6.2500e-05\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0608 - loss: 0.0014 - val_accuracy: 0.3208 - val_loss: 0.0183 - learning_rate: 6.2500e-05\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00611\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0605 - loss: 0.0019 - val_accuracy: 0.3365 - val_loss: 0.0184 - learning_rate: 6.2500e-05\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "\n",
      "Fold 3 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[477   0]\n",
      " [  1 476]]\n",
      "TN=477, FP=0, FN=1, TP=476\n",
      "\n",
      "Fold 3 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9990\n",
      "Precision   : 1.0000  (class 1: Professional)\n",
      "Sensitivity : 0.9979     (Recall for class 1)\n",
      "Specificity : 1.0000 (for class 0: Amateur)\n",
      "F1-score    : 0.9990\n",
      "\n",
      "==========================================================================================\n",
      "Fold 4 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_72            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_9\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_73            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_75            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_28               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_74            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_76            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_18              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_29               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_77            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_19              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_9            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ dropout_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│                                   │                              │                   │ dense_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_19            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_78            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_9\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_79            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_72            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_45 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_72[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_9\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_18 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_9 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_73            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_46 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_73[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_75            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_28               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_48 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_75[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_74            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_9 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_47 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_74[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_27 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_76            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_18              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_76[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_29               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_77            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_49 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_77[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_19              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_19 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_9            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_9[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_28 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ dropout_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_18[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_18[\u001b[38;5;34m0\u001b[0m][\n",
       "│                                   │                              │                   │ dense_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_19            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_19[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_78            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_9\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_78[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_79            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_79[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 4...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.72237, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 239ms/step - accuracy: 0.0000e+00 - loss: 0.3498 - val_accuracy: 0.0000e+00 - val_loss: 3.7224 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 3.72237 to 0.95690, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 186ms/step - accuracy: 5.2411e-04 - loss: 0.0935 - val_accuracy: 0.0000e+00 - val_loss: 0.9569 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.95690 to 0.19201, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 183ms/step - accuracy: 0.0024 - loss: 0.0535 - val_accuracy: 0.0021 - val_loss: 0.1920 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.19201\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0047 - loss: 0.0495 - val_accuracy: 0.0472 - val_loss: 0.2882 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.19201 to 0.09145, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 183ms/step - accuracy: 0.0063 - loss: 0.0451 - val_accuracy: 0.0597 - val_loss: 0.0914 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.09145 to 0.06681, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - accuracy: 0.0092 - loss: 0.0298 - val_accuracy: 0.1237 - val_loss: 0.0668 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.06681 to 0.06148, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - accuracy: 0.0162 - loss: 0.0316 - val_accuracy: 0.1017 - val_loss: 0.0615 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.06148\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0176 - loss: 0.0261 - val_accuracy: 0.2002 - val_loss: 0.0828 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.06148\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0197 - loss: 0.0381 - val_accuracy: 0.2421 - val_loss: 0.0740 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06148\n",
      "120/120 - 23s - 190ms/step - accuracy: 0.0128 - loss: 0.0238 - val_accuracy: 0.4623 - val_loss: 0.2619 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.06148 to 0.03070, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - accuracy: 0.0131 - loss: 0.0292 - val_accuracy: 0.3208 - val_loss: 0.0307 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.03070\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0121 - loss: 0.0245 - val_accuracy: 0.0073 - val_loss: 0.0372 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.03070\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0100 - loss: 0.0209 - val_accuracy: 0.2862 - val_loss: 0.0832 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.03070\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0126 - loss: 0.0148 - val_accuracy: 0.0608 - val_loss: 0.0503 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.03070\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0186 - loss: 0.0100 - val_accuracy: 0.2086 - val_loss: 0.0341 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.03070 to 0.00495, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - accuracy: 0.0252 - loss: 0.0104 - val_accuracy: 0.0535 - val_loss: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0301 - loss: 0.0044 - val_accuracy: 0.1614 - val_loss: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0338 - loss: 0.0027 - val_accuracy: 0.1122 - val_loss: 0.0101 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0351 - loss: 0.0022 - val_accuracy: 0.1803 - val_loss: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0362 - loss: 0.0020 - val_accuracy: 0.0901 - val_loss: 0.0127 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0377 - loss: 0.0016 - val_accuracy: 0.1122 - val_loss: 0.0120 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0422 - loss: 0.0011 - val_accuracy: 0.1583 - val_loss: 0.0128 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0456 - loss: 7.6783e-04 - val_accuracy: 0.1237 - val_loss: 0.0144 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0480 - loss: 0.0013 - val_accuracy: 0.0922 - val_loss: 0.0156 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0432 - loss: 0.0014 - val_accuracy: 0.1530 - val_loss: 0.0134 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0493 - loss: 7.9872e-04 - val_accuracy: 0.1279 - val_loss: 0.0140 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0577 - loss: 5.2888e-04 - val_accuracy: 0.1268 - val_loss: 0.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0519 - loss: 7.7148e-04 - val_accuracy: 0.1352 - val_loss: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0540 - loss: 0.0011 - val_accuracy: 0.1426 - val_loss: 0.0139 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0527 - loss: 6.7907e-04 - val_accuracy: 0.1268 - val_loss: 0.0143 - learning_rate: 6.2500e-05\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00495\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0521 - loss: 4.3683e-04 - val_accuracy: 0.1342 - val_loss: 0.0141 - learning_rate: 6.2500e-05\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n",
      "\n",
      "Fold 4 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[476   1]\n",
      " [  0 477]]\n",
      "TN=476, FP=1, FN=0, TP=477\n",
      "\n",
      "Fold 4 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9990\n",
      "Precision   : 0.9979  (class 1: Professional)\n",
      "Sensitivity : 1.0000     (Recall for class 1)\n",
      "Specificity : 0.9979 (for class 0: Amateur)\n",
      "F1-score    : 0.9990\n",
      "\n",
      "==========================================================================================\n",
      "Fold 5 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_30               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_80            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_1\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_81            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_83            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_82            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ activation_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_84            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_20              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_85            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_21              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_10           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ dropout_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_20            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│                                   │                              │                   │ dense_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_21            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_86            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_1\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_87            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_30               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_80            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_50 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_80[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_1\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_20 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_10 (\u001b[38;5;33mMultiply\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_81            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_51 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_81[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_83            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_53 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_83[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_82            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_10 (\u001b[38;5;33mLambda\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_52 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_82[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ activation_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_84            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_20              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_84[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_85            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_54 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_85[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_21              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_21 (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_10           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_10[\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ dropout_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_20            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_20[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_20[\u001b[38;5;34m0\u001b[0m][\n",
       "│                                   │                              │                   │ dense_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_21            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_21[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_86            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_1\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_86[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_87            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_87[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 5...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 2.74710, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 241ms/step - accuracy: 0.0000e+00 - loss: 0.3645 - val_accuracy: 0.0000e+00 - val_loss: 2.7471 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 2.74710 to 2.48446, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 179ms/step - accuracy: 5.2411e-04 - loss: 0.1228 - val_accuracy: 0.0000e+00 - val_loss: 2.4845 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 2.48446 to 0.17561, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0037 - loss: 0.0683 - val_accuracy: 0.0000e+00 - val_loss: 0.1756 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17561 to 0.08833, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 179ms/step - accuracy: 0.0045 - loss: 0.0419 - val_accuracy: 0.0000e+00 - val_loss: 0.0883 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.08833 to 0.03399, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0031 - loss: 0.0498 - val_accuracy: 0.2610 - val_loss: 0.0340 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.03399\n",
      "120/120 - 23s - 191ms/step - accuracy: 0.0039 - loss: 0.0398 - val_accuracy: 0.2945 - val_loss: 0.0741 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.03399 to 0.02813, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 191ms/step - accuracy: 0.0045 - loss: 0.0311 - val_accuracy: 0.0052 - val_loss: 0.0281 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.02813 to 0.01788, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 24s - 198ms/step - accuracy: 0.0037 - loss: 0.0254 - val_accuracy: 0.0776 - val_loss: 0.0179 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01788\n",
      "120/120 - 23s - 193ms/step - accuracy: 0.0142 - loss: 0.0342 - val_accuracy: 0.0409 - val_loss: 0.0305 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01788\n",
      "120/120 - 23s - 188ms/step - accuracy: 0.0068 - loss: 0.0217 - val_accuracy: 0.3050 - val_loss: 0.0346 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01788\n",
      "120/120 - 23s - 190ms/step - accuracy: 0.0076 - loss: 0.0195 - val_accuracy: 0.0556 - val_loss: 0.1288 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01788\n",
      "120/120 - 23s - 191ms/step - accuracy: 0.0079 - loss: 0.0236 - val_accuracy: 0.0922 - val_loss: 0.0477 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.01788\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0079 - loss: 0.0234 - val_accuracy: 0.0052 - val_loss: 0.0281 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01788\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0034 - loss: 0.0107 - val_accuracy: 0.0157 - val_loss: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01788\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0079 - loss: 0.0045 - val_accuracy: 0.0828 - val_loss: 0.0311 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.01788\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0084 - loss: 0.0036 - val_accuracy: 0.0419 - val_loss: 0.0273 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.01788 to 0.01431, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 180ms/step - accuracy: 0.0097 - loss: 0.0026 - val_accuracy: 0.0294 - val_loss: 0.0143 - learning_rate: 2.5000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0105 - loss: 0.0028 - val_accuracy: 0.0430 - val_loss: 0.0157 - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01431\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0079 - loss: 0.0041 - val_accuracy: 0.1006 - val_loss: 0.0265 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01431\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0115 - loss: 0.0014 - val_accuracy: 0.0451 - val_loss: 0.0237 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01431\n",
      "120/120 - 134s - 1s/step - accuracy: 0.0131 - loss: 0.0026 - val_accuracy: 0.0210 - val_loss: 0.0284 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01431\n",
      "120/120 - 25s - 208ms/step - accuracy: 0.0102 - loss: 0.0021 - val_accuracy: 0.0503 - val_loss: 0.0215 - learning_rate: 1.2500e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01431\n",
      "120/120 - 23s - 194ms/step - accuracy: 0.0118 - loss: 0.0024 - val_accuracy: 0.0755 - val_loss: 0.0223 - learning_rate: 1.2500e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0126 - loss: 0.0017 - val_accuracy: 0.0828 - val_loss: 0.0247 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01431\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0100 - loss: 0.0013 - val_accuracy: 0.0493 - val_loss: 0.0260 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0136 - loss: 0.0013 - val_accuracy: 0.0440 - val_loss: 0.0242 - learning_rate: 6.2500e-05\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01431\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0134 - loss: 0.0012 - val_accuracy: 0.0409 - val_loss: 0.0233 - learning_rate: 6.2500e-05\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0152 - loss: 0.0012 - val_accuracy: 0.0409 - val_loss: 0.0234 - learning_rate: 6.2500e-05\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0110 - loss: 9.9509e-04 - val_accuracy: 0.0231 - val_loss: 0.0238 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0107 - loss: 7.4194e-04 - val_accuracy: 0.0273 - val_loss: 0.0239 - learning_rate: 3.1250e-05\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.01431\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0144 - loss: 8.4973e-04 - val_accuracy: 0.0314 - val_loss: 0.0234 - learning_rate: 3.1250e-05\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.01431\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0134 - loss: 8.3771e-04 - val_accuracy: 0.0325 - val_loss: 0.0239 - learning_rate: 3.1250e-05\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
      "\n",
      "Fold 5 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[476   1]\n",
      " [  2 475]]\n",
      "TN=476, FP=1, FN=2, TP=475\n",
      "\n",
      "Fold 5 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9969\n",
      "Precision   : 0.9979  (class 1: Professional)\n",
      "Sensitivity : 0.9958     (Recall for class 1)\n",
      "Specificity : 0.9979 (for class 0: Amateur)\n",
      "F1-score    : 0.9969\n",
      "\n",
      "=== Per-Fold Metrics Summary ===\n",
      "Fold 1: Acc=1.0000, Prec=1.0000, Sens=1.0000, Spec=1.0000, F1=1.0000 | TN=477 FP=0 FN=0 TP=477\n",
      "Fold 2: Acc=0.9990, Prec=1.0000, Sens=0.9979, Spec=1.0000, F1=0.9990 | TN=477 FP=0 FN=1 TP=476\n",
      "Fold 3: Acc=0.9990, Prec=1.0000, Sens=0.9979, Spec=1.0000, F1=0.9990 | TN=477 FP=0 FN=1 TP=476\n",
      "Fold 4: Acc=0.9990, Prec=0.9979, Sens=1.0000, Spec=0.9979, F1=0.9990 | TN=476 FP=1 FN=0 TP=477\n",
      "Fold 5: Acc=0.9969, Prec=0.9979, Sens=0.9958, Spec=0.9979, F1=0.9969 | TN=476 FP=1 FN=2 TP=475\n",
      "\n",
      "=== Mean ± Std over 5 folds ===\n",
      "Accuracy    : 0.9987 ± 0.0010\n",
      "Precision   : 0.9992 ± 0.0010\n",
      "Sensitivity : 0.9983 ± 0.0016\n",
      "Specificity : 0.9992 ± 0.0010\n",
      "F1-score    : 0.9987 ± 0.0010\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 3 (training): 5-fold CV with per-fold confusion matrix + metrics =====\n",
    "\n",
    "EPOCHS = 200                                                                   # Upper bound; EarlyStopping will cut earlier\n",
    "BATCH_SIZE = 32                                                                # Batch size\n",
    "\n",
    "per_fold_metrics = []                                                          # List to store per-fold metric dicts\n",
    "histories = []                                                                 # Store Keras history dicts per fold\n",
    "\n",
    "fold = 0                                                                       # Initialize fold counter\n",
    "for train_idx, val_idx in skf.split(X, y):                                     # Iterate stratified folds\n",
    "    fold += 1                                                                  # Increment fold number\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)                                                       # Visual separator\n",
    "    print(f\"Fold {fold} — Train/Val split\")                                    # Announce fold\n",
    "    print(\"Train idx:\", train_idx.shape, \"Val idx:\", val_idx.shape)            # Show split sizes\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]                                  # Slice EEG training/val data\n",
    "    y_train, y_val = y[train_idx], y[val_idx]                                  # Slice labels training/val\n",
    "\n",
    "    print(\"X_train:\", X_train.shape, \"| y_train:\", y_train.shape)              # Print shapes\n",
    "    print(\"X_val  :\", X_val.shape,   \"| y_val  :\", y_val.shape)                # Print shapes\n",
    "\n",
    "    model = compile_model()                                                    # Build + compile model\n",
    "    callbacks = make_callbacks(fold)                                           # Create callbacks for this fold\n",
    "\n",
    "    print(\"Training with EarlyStopping...\")                                    # Status\n",
    "    history = model.fit(                                                       # Fit model\n",
    "        X_train, y_train,                                                      # Train data\n",
    "        validation_data=(X_val, y_val),                                        # Validation data\n",
    "        epochs=EPOCHS,                                                         # Max epochs\n",
    "        batch_size=BATCH_SIZE,                                                 # Batch size\n",
    "        callbacks=callbacks,                                                   # Callbacks list\n",
    "        verbose=2                                                              # Per-epoch logs\n",
    "    )\n",
    "\n",
    "    histories.append(history.history)                                          # Store training history dict\n",
    "\n",
    "    print(\"Predicting on validation fold...\")                                  # Status\n",
    "    y_prob = model.predict(X_val, batch_size=BATCH_SIZE).ravel()               # Predict probabilities\n",
    "    y_pred = (y_prob >= 0.5).astype(int)                                       # Threshold at 0.5 to get classes\n",
    "\n",
    "    # ----- Confusion Matrix & Per-fold Metrics -----\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=[0, 1])                        # Confusion matrix with label order [0,1]\n",
    "    tn, fp, fn, tp = cm.ravel()                                                # Unpack counts\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\")\n",
    "    print(cm)                                                                  # Print matrix\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")                               # Print counts\n",
    "\n",
    "    acc  = accuracy_score(y_val, y_pred)                                       # Accuracy\n",
    "    prec = precision_score(y_val, y_pred, pos_label=1, zero_division=0)        # Precision (class 1)\n",
    "    sens = recall_score(y_val, y_pred,    pos_label=1, zero_division=0)        # Sensitivity/Recall (class 1)\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0                            # Specificity (class 0)\n",
    "    f1   = f1_score(y_val, y_pred, pos_label=1, zero_division=0)               # F1-score (class 1)\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Metrics (threshold=0.5):\")                          # Header\n",
    "    print(f\"Accuracy    : {acc:.4f}\")                                          # Accuracy\n",
    "    print(f\"Precision   : {prec:.4f}  (class 1: Professional)\")                # Precision\n",
    "    print(f\"Sensitivity : {sens:.4f}     (Recall for class 1)\")                # Sensitivity/Recall\n",
    "    print(f\"Specificity : {spec:.4f} (for class 0: Amateur)\")                  # Specificity\n",
    "    print(f\"F1-score    : {f1:.4f}\")                                           # F1\n",
    "\n",
    "    per_fold_metrics.append({                                                  # Save per-fold metrics\n",
    "        \"fold\": fold, \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
    "        \"accuracy\": float(acc), \"precision\": float(prec),\n",
    "        \"sensitivity\": float(sens), \"specificity\": float(spec), \"f1\": float(f1)\n",
    "    })\n",
    "\n",
    "# ----- Per-fold summary printout -----\n",
    "print(\"\\n=== Per-Fold Metrics Summary ===\")                                     # Header\n",
    "for m in per_fold_metrics:                                                      # Iterate per-fold metrics\n",
    "    print(f\"Fold {m['fold']}: \"\n",
    "          f\"Acc={m['accuracy']:.4f}, \"\n",
    "          f\"Prec={m['precision']:.4f}, \"\n",
    "          f\"Sens={m['sensitivity']:.4f}, \"\n",
    "          f\"Spec={m['specificity']:.4f}, \"\n",
    "          f\"F1={m['f1']:.4f} | \"\n",
    "          f\"TN={m['tn']} FP={m['fp']} FN={m['fn']} TP={m['tp']}\")               # Pretty per-fold line\n",
    "\n",
    "# ----- Optional overall mean ± std across folds -----\n",
    "accs  = [m[\"accuracy\"]    for m in per_fold_metrics]                            # Collect accuracies\n",
    "precs = [m[\"precision\"]   for m in per_fold_metrics]                            # Collect precisions\n",
    "sens  = [m[\"sensitivity\"] for m in per_fold_metrics]                            # Collect sensitivities\n",
    "specs = [m[\"specificity\"] for m in per_fold_metrics]                            # Collect specificities\n",
    "f1s   = [m[\"f1\"]          for m in per_fold_metrics]                            # Collect F1 scores\n",
    "\n",
    "print(\"\\n=== Mean ± Std over 5 folds ===\")                                      # Header\n",
    "print(f\"Accuracy    : {np.mean(accs):.4f} ± {np.std(accs):.4f}\")                # Mean±Std accuracy\n",
    "print(f\"Precision   : {np.mean(precs):.4f} ± {np.std(precs):.4f}\")              # Mean±Std precision\n",
    "print(f\"Sensitivity : {np.mean(sens):.4f} ± {np.std(sens):.4f}\")                # Mean±Std sensitivity\n",
    "print(f\"Specificity : {np.mean(specs):.4f} ± {np.std(specs):.4f}\")              # Mean±Std specificity\n",
    "print(f\"F1-score    : {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")                  # Mean±Std F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec6fa8-298e-46da-9d42-5cea60280a8b",
   "metadata": {},
   "source": [
    "Step 6 : Plot training vs validation Accuracy and Loss across folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d901e58-454b-4d2e-8497-733977c1be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History keys detected -> acc_key: accuracy | val_acc_key: val_accuracy | loss_key: loss | val_loss_key: val_loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Step 4: Plot training/validation accuracy and loss across folds =====\n",
    "\n",
    "def get_key(d, *candidates):\n",
    "    \"\"\"Return the first existing key from candidates (handles TF version differences).\"\"\"\n",
    "    for k in candidates:                         # Iterate candidate keys\n",
    "        if k in d:                               # If key exists in dict\n",
    "            return k                             # Return it\n",
    "    return None                                  # If none found, return None\n",
    "\n",
    "# Detect metric keys (could be 'accuracy'/'acc' depending on TF/Keras version)\n",
    "acc_key      = get_key(histories[0], 'accuracy', 'acc')      # Training accuracy key\n",
    "val_acc_key  = get_key(histories[0], 'val_accuracy', 'val_acc')  # Validation accuracy key\n",
    "loss_key     = 'loss'                                        # Training loss key\n",
    "val_loss_key = 'val_loss'                                    # Validation loss key\n",
    "\n",
    "print(\"History keys detected ->\",\n",
    "      \"acc_key:\", acc_key, \"| val_acc_key:\", val_acc_key,\n",
    "      \"| loss_key:\", loss_key, \"| val_loss_key:\", val_loss_key)  # Show detected keys\n",
    "\n",
    "# ---- Plot Accuracy ----\n",
    "plt.figure(figsize=(7,5))                                     # Create figure\n",
    "max_len = max(len(h[acc_key]) for h in histories)             # Longest run across folds\n",
    "xs = np.arange(1, max_len+1)                                  # X-axis (epoch indices)\n",
    "\n",
    "acc_curves, val_acc_curves = [], []                           # Lists to accumulate padded curves\n",
    "\n",
    "for i, h in enumerate(histories, start=1):                    # For each fold history\n",
    "    a  = np.array(h[acc_key], dtype=float)                    # Train acc per epoch\n",
    "    va = np.array(h[val_acc_key], dtype=float)                # Val acc per epoch\n",
    "    acc_curves.append(np.pad(a,  (0, max_len - len(a)),  constant_values=np.nan))   # Pad train acc\n",
    "    val_acc_curves.append(np.pad(va, (0, max_len - len(va)), constant_values=np.nan))  # Pad val acc\n",
    "    plt.plot(np.arange(1, len(a)+1),  a,  alpha=0.5, label=f\"Fold {i} Train\" if i==1 else None)   # Plot fold train\n",
    "    plt.plot(np.arange(1, len(va)+1), va, alpha=0.8, linestyle='--', label=f\"Fold {i} Val\" if i==1 else None)  # Plot fold val\n",
    "\n",
    "mean_acc = np.nanmean(np.vstack(acc_curves), axis=0)         # Mean train acc across folds\n",
    "mean_val_acc = np.nanmean(np.vstack(val_acc_curves), axis=0) # Mean val acc across folds\n",
    "plt.plot(xs, mean_acc, linewidth=2.5, label=\"Mean Train\")     # Plot mean train\n",
    "plt.plot(xs, mean_val_acc, linewidth=2.5, linestyle='--', label=\"Mean Val\")  # Plot mean val\n",
    "\n",
    "plt.title(\"Training vs Validation Accuracy (5-fold CV)\")      # Title\n",
    "plt.xlabel(\"Epoch\")                                           # X label\n",
    "plt.ylabel(\"Accuracy\")                                        # Y label\n",
    "plt.legend()                                                  # Legend\n",
    "plt.grid(True, alpha=0.3)                                     # Grid\n",
    "plt.tight_layout()                                            # Layout\n",
    "plt.show()                                                    # Render\n",
    "\n",
    "# ---- Plot Loss ----\n",
    "plt.figure(figsize=(7,5))                                     # Create figure\n",
    "max_len = max(len(h[loss_key]) for h in histories)            # Longest run across folds\n",
    "xs = np.arange(1, max_len+1)                                  # X-axis\n",
    "\n",
    "loss_curves, val_loss_curves = [], []                         # Lists to accumulate padded loss\n",
    "\n",
    "for i, h in enumerate(histories, start=1):                    # For each fold history\n",
    "    l  = np.array(h[loss_key], dtype=float)                   # Train loss per epoch\n",
    "    vl = np.array(h[val_loss_key], dtype=float)               # Val loss per epoch\n",
    "    loss_curves.append(np.pad(l,  (0, max_len - len(l)),  constant_values=np.nan))   # Pad train loss\n",
    "    val_loss_curves.append(np.pad(vl, (0, max_len - len(vl)), constant_values=np.nan))  # Pad val loss\n",
    "    plt.plot(np.arange(1, len(l)+1),  l,  alpha=0.5, label=f\"Fold {i} Train Loss\" if i==1 else None)  # Plot train\n",
    "    plt.plot(np.arange(1, len(vl)+1), vl, alpha=0.8, linestyle='--', label=f\"Fold {i} Val Loss\" if i==1 else None)  # Plot val\n",
    "\n",
    "mean_loss = np.nanmean(np.vstack(loss_curves), axis=0)        # Mean train loss across folds\n",
    "mean_val_loss = np.nanmean(np.vstack(val_loss_curves), axis=0)# Mean val loss across folds\n",
    "plt.plot(xs, mean_loss, linewidth=2.5, label=\"Mean Train Loss\")             # Plot mean train loss\n",
    "plt.plot(xs, mean_val_loss, linewidth=2.5, linestyle='--', label=\"Mean Val Loss\")  # Plot mean val loss\n",
    "\n",
    "plt.title(\"Training vs Validation Loss (5-fold CV)\")          # Title\n",
    "plt.xlabel(\"Epoch\")                                           # X label\n",
    "plt.ylabel(\"Loss\")                                            # Y label\n",
    "plt.legend()                                                  # Legend\n",
    "plt.grid(True, alpha=0.3)                                     # Grid\n",
    "plt.tight_layout()                                            # Layout\n",
    "plt.show()                                                    # Render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cbf56-870a-4aed-bd6f-8731b6a00c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
