{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d3cb4b-2b03-4283-87bf-b807e7c10d23",
   "metadata": {},
   "source": [
    "step 1- Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac08b3e9-3cf8-4469-bf1e-f8a3a6884e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 1: Imports, seeds, and GPU setup =====\n",
    "\n",
    "# Standard libraries\n",
    "import os, random                              # OS utilities and reproducibility\n",
    "import numpy as np                             # Numerical arrays\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf                        # Main DL framework\n",
    "\n",
    "# Keras layers & utilities\n",
    "from tensorflow.keras.layers import (Input, SeparableConv2D, DepthwiseConv2D, BatchNormalization,\n",
    "                                     Activation, AveragePooling2D, Dropout, Dense, Add, Lambda,\n",
    "                                     GlobalAveragePooling2D, GlobalAveragePooling1D,\n",
    "                                     MultiHeadAttention, Reshape, LayerNormalization, Conv2D)\n",
    "from tensorflow.keras.models import Model      # Functional model API\n",
    "from tensorflow.keras.optimizers import Adam   # Optimizer\n",
    "from tensorflow.keras.losses import BinaryCrossentropy  # Binary classification loss\n",
    "from tensorflow.keras.metrics import Accuracy  # Accuracy metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # Training callbacks\n",
    "from tensorflow.keras import backend as K      # Keras backend for static shape queries\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import StratifiedKFold                  # Stratified 5-fold CV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score  # Metrics\n",
    "\n",
    "# Plotting (optional)\n",
    "import matplotlib.pyplot as plt               # For charts (optional)\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42                                     # Fixed seed\n",
    "np.random.seed(SEED)                          # Seed NumPy\n",
    "tf.random.set_seed(SEED)                      # Seed TensorFlow\n",
    "random.seed(SEED)                             # Seed Python\n",
    "\n",
    "# Optional: make TensorFlow gentle with GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU') # Detect GPUs\n",
    "print(\"TensorFlow:\", tf.__version__)          # Show TF version\n",
    "print(\"GPUs:\", gpus)                          # Show detected GPUs\n",
    "if gpus:                                      # If GPU(s) are present\n",
    "    for g in gpus:                            # Iterate each GPU\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(g, True)  # Enable memory growth\n",
    "        except Exception as e:\n",
    "            print(\"GPU memory growth not set:\", e)             # Warn if not possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07e80a-cf10-4e44-8609-3a8acc6c6a34",
   "metadata": {},
   "source": [
    "Step 2- Load arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f8364b-fe04-40e2-b139-7275af0eaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "Loaded.\n",
      "Raw X shape: (4770, 14, 200) | dtype: float64\n",
      "Raw y shape: (4770,) | dtype: int64\n",
      "y squeezed shape: (4770,) | unique labels: [0 1]\n",
      "X after adding channel dim: (4770, 14, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 2: Load the arrays in the given path (no normalization) =====\n",
    "\n",
    "# Exact Windows paths you provided (raw strings to avoid backslash escapes)\n",
    "eeg_path    = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_pp.npy\"\n",
    "labels_path = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_labels.npy\"\n",
    "\n",
    "print(\"Loading EEG data...\")                 # Status print\n",
    "X = np.load(eeg_path)                        # Load EEG data, expected shape (N, 14, 200)\n",
    "y = np.load(labels_path)                     # Load labels, expected shape (N,) or (N,1)\n",
    "print(\"Loaded.\")                             # Confirm loaded\n",
    "\n",
    "print(\"Raw X shape:\", X.shape, \"| dtype:\", X.dtype)  # Inspect EEG tensor\n",
    "print(\"Raw y shape:\", y.shape, \"| dtype:\", y.dtype)  # Inspect labels\n",
    "\n",
    "y = np.squeeze(y).astype(int)                # Ensure labels are 1D int array\n",
    "print(\"y squeezed shape:\", y.shape, \"| unique labels:\", np.unique(y))  # Show label distribution\n",
    "\n",
    "# Sanity checks on shapes and labels\n",
    "assert X.ndim == 3, f\"Expected X to be (N,14,200). Got {X.shape}\"      # Check rank\n",
    "assert X.shape[1] == 14 and X.shape[2] == 200, \"Expected 14 electrodes and 200 samples per segment.\"  # Check dims\n",
    "assert set(np.unique(y)).issubset({0,1}), \"Labels must be {0,1}.\"      # Binary check\n",
    "\n",
    "# Add channel dimension for Keras Conv2D: (N, 14, 200, 1)\n",
    "X = X[..., np.newaxis]                         # Append channel dim\n",
    "print(\"X after adding channel dim:\", X.shape)  # Verify final input shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1573ae-b7d7-46c2-b447-948c63bd620b",
   "metadata": {},
   "source": [
    "Step 3: Normalising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da717924-cc93-47c0-b426-a429d850f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 3: Normalization helper (per-fold; compute stats on train only) =====\n",
    "\n",
    "def normalize_per_fold(X_train, X_val, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Normalizes X_train and X_val using mean/std computed from X_train only.\n",
    "    Broadcasting shape is (1, 14, 1, 1), i.e., per-electrode normalization.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute mean & std from the training set only\n",
    "    train_mean = np.mean(X_train, axis=(0, 2, 3), keepdims=True)   # -> (1, 14, 1, 1)\n",
    "    train_std  = np.std( X_train, axis=(0, 2, 3), keepdims=True)   # -> (1, 14, 1, 1)\n",
    "\n",
    "    # Safety: avoid division by (near) zero\n",
    "    train_std = np.where(train_std < eps, 1.0, train_std)\n",
    "\n",
    "    # Step 2: Apply normalization using training mean & std\n",
    "    X_train_norm = ((X_train - train_mean) / train_std).astype(np.float32)\n",
    "    X_val_norm   = ((X_val   - train_mean) / train_std).astype(np.float32)\n",
    "\n",
    "    print(\"Per-fold normalization done.\",\n",
    "          \"train_mean shape:\", train_mean.shape, \"train_std shape:\", train_std.shape)\n",
    "\n",
    "    return X_train_norm, X_val_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2af7b-1685-4573-b263-604591d7918e",
   "metadata": {},
   "source": [
    "Step 4: Prepare 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7727ac88-2626-48a3-ad00-30da848d423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared StratifiedKFold with 5 splits.\n",
      "Total samples: 4770\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 4: Prepare the data to perform 5-fold cross validation =====\n",
    "\n",
    "N_SPLITS = 5                                   # Number of CV folds\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS,       # Stratified (preserves class ratios)\n",
    "                      shuffle=True,            # Shuffle before splitting\n",
    "                      random_state=SEED)       # Reproducible splits\n",
    "\n",
    "print(f\"Prepared StratifiedKFold with {N_SPLITS} splits.\")  # Status\n",
    "print(\"Total samples:\", X.shape[0])                         # Dataset size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e50d7-72cd-41ee-94b4-207be8e301f7",
   "metadata": {},
   "source": [
    "Step 5: Model, compile, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82374f63-b924-4a09-837f-d6dbbbf5c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: EEGNet (generalized to your data shape) =====\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, DepthwiseConv2D, SeparableConv2D, BatchNormalization,\n",
    "    Activation, AveragePooling2D, Flatten, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_cnn_model(input_shape, dropout_rate=0.5, num_classes=1, lr=1e-3):\n",
    "    \"\"\"\n",
    "    EEGNet-like CNN generalized for input_shape=(n_channels, n_times, 1).\n",
    "    Uses a depthwise spatial kernel that matches n_channels automatically.\n",
    "    \"\"\"\n",
    "    n_channels, n_times, _ = input_shape\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Temporal filtering\n",
    "    # Keep a reasonable temporal kernel, pad='same' so it works for short/long segments.\n",
    "    x = Conv2D(16, (1, min(64, max(3, n_times))), padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Spatial depthwise conv over electrodes (kernel height = n_channels)\n",
    "    x = DepthwiseConv2D((n_channels, 1), depth_multiplier=2, padding='valid', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = AveragePooling2D((1, 4))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Separable conv (spatio-temporal refinement)\n",
    "    # Keep time kernel modest; cap at 16.\n",
    "    x = SeparableConv2D(16, (1, min(16, max(3, n_times // 10))), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = AveragePooling2D((1, 8))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Classifier head\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)  # binary classification\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def make_callbacks(fold_idx):\n",
    "    \"\"\"EarlyStopping + ReduceLROnPlateau + ModelCheckpoint(.h5)\"\"\"\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    rlrop = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=4,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    ckpt = ModelCheckpoint(\n",
    "        filepath=f\"best_fold_{fold_idx}.h5\",\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    return [es, rlrop, ckpt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f00bd69-f2b6-46ad-bbdf-8ef39459547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Fold 1 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(-0.0000, 1.0000) | Val(mean,std)=(-0.0004, 1.0616) | Train per-electrode std range: [1.000, 1.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)                             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d (\u001b[38;5;33mSeparableConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_1 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,025</span> (35.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,025\u001b[0m (35.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,897</span> (34.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,897\u001b[0m (34.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.61438, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 8s - 67ms/step - accuracy: 0.6939 - loss: 0.6149 - val_accuracy: 0.6950 - val_loss: 0.6144 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61438 to 0.36869, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.8412 - loss: 0.4157 - val_accuracy: 0.8470 - val_loss: 0.3687 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.36869 to 0.17251, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9002 - loss: 0.2595 - val_accuracy: 0.9361 - val_loss: 0.1725 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17251 to 0.09272, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9334 - loss: 0.1809 - val_accuracy: 0.9748 - val_loss: 0.0927 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.09272 to 0.06042, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9568 - loss: 0.1261 - val_accuracy: 0.9885 - val_loss: 0.0604 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.06042\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9657 - loss: 0.1010 - val_accuracy: 0.9906 - val_loss: 0.0613 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.06042 to 0.02723, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9691 - loss: 0.0861 - val_accuracy: 0.9937 - val_loss: 0.0272 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.02723\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9738 - loss: 0.0703 - val_accuracy: 0.9916 - val_loss: 0.0479 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.02723\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9733 - loss: 0.0787 - val_accuracy: 0.9832 - val_loss: 0.0920 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.02723\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9814 - loss: 0.0581 - val_accuracy: 0.9937 - val_loss: 0.0365 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.02723\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9759 - loss: 0.0610 - val_accuracy: 0.9937 - val_loss: 0.0316 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.02723 to 0.01975, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9882 - loss: 0.0363 - val_accuracy: 0.9948 - val_loss: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.01975 to 0.01795, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9874 - loss: 0.0359 - val_accuracy: 0.9958 - val_loss: 0.0179 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss improved from 0.01795 to 0.01441, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9903 - loss: 0.0353 - val_accuracy: 0.9969 - val_loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.01441 to 0.00432, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9903 - loss: 0.0260 - val_accuracy: 0.9990 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00432\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9877 - loss: 0.0333 - val_accuracy: 0.9979 - val_loss: 0.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9908 - loss: 0.0296 - val_accuracy: 0.9969 - val_loss: 0.0154 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9906 - loss: 0.0260 - val_accuracy: 0.9969 - val_loss: 0.0125 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9932 - loss: 0.0209 - val_accuracy: 0.9979 - val_loss: 0.0115 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9955 - loss: 0.0166 - val_accuracy: 0.9979 - val_loss: 0.0137 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9950 - loss: 0.0161 - val_accuracy: 0.9969 - val_loss: 0.0127 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9940 - loss: 0.0226 - val_accuracy: 0.9969 - val_loss: 0.0189 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.9969 - val_loss: 0.0149 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00432\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9937 - loss: 0.0207 - val_accuracy: 0.9979 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9945 - loss: 0.0178 - val_accuracy: 0.9979 - val_loss: 0.0113 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9979 - val_loss: 0.0162 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.9969 - val_loss: 0.0161 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9937 - loss: 0.0179 - val_accuracy: 0.9979 - val_loss: 0.0125 - learning_rate: 6.2500e-05\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9934 - loss: 0.0179 - val_accuracy: 0.9979 - val_loss: 0.0110 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00432\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9942 - loss: 0.0149 - val_accuracy: 0.9979 - val_loss: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Fold 1 Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\n",
      "[[477   0]\n",
      " [  1 476]]\n",
      "TN=477, FP=0, FN=1, TP=476\n",
      "\n",
      "Fold 1 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9990\n",
      "Precision   : 1.0000  (class 1)\n",
      "Sensitivity : 0.9979  (Recall for class 1)\n",
      "Specificity : 1.0000  (for class 0)\n",
      "F1-score    : 0.9990\n",
      "\n",
      "==========================================================================================\n",
      "Fold 2 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(-0.0007, 1.0084) | Train per-electrode std range: [1.000, 1.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_3 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_1 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_4 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_2 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_1 (\u001b[38;5;33mSeparableConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_5 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_3 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,025</span> (35.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,025\u001b[0m (35.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,897</span> (34.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,897\u001b[0m (34.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.69280, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 7s - 56ms/step - accuracy: 0.7175 - loss: 0.5553 - val_accuracy: 0.5409 - val_loss: 0.6928 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69280 to 0.60492, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.8771 - loss: 0.3224 - val_accuracy: 0.6771 - val_loss: 0.6049 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60492 to 0.22302, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9287 - loss: 0.2111 - val_accuracy: 0.9182 - val_loss: 0.2230 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.22302 to 0.10614, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9497 - loss: 0.1493 - val_accuracy: 0.9727 - val_loss: 0.1061 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.10614 to 0.07711, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9510 - loss: 0.1344 - val_accuracy: 0.9769 - val_loss: 0.0771 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.07711 to 0.05311, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9575 - loss: 0.1169 - val_accuracy: 0.9864 - val_loss: 0.0531 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.05311 to 0.04050, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9667 - loss: 0.0875 - val_accuracy: 0.9885 - val_loss: 0.0405 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.04050\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9654 - loss: 0.0890 - val_accuracy: 0.9864 - val_loss: 0.0452 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.04050\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9725 - loss: 0.0726 - val_accuracy: 0.9843 - val_loss: 0.0539 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.04050\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9756 - loss: 0.0738 - val_accuracy: 0.9885 - val_loss: 0.0408 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.04050\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9788 - loss: 0.0594 - val_accuracy: 0.9885 - val_loss: 0.0448 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.04050 to 0.03887, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9803 - loss: 0.0547 - val_accuracy: 0.9906 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.03887 to 0.03876, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9772 - loss: 0.0555 - val_accuracy: 0.9916 - val_loss: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.03876\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9801 - loss: 0.0543 - val_accuracy: 0.9906 - val_loss: 0.0502 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.03876\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9806 - loss: 0.0525 - val_accuracy: 0.9906 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.03876\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9874 - loss: 0.0360 - val_accuracy: 0.9916 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.03876\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9830 - loss: 0.0442 - val_accuracy: 0.9906 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.03876 to 0.03172, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9819 - loss: 0.0454 - val_accuracy: 0.9916 - val_loss: 0.0317 - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9890 - loss: 0.0294 - val_accuracy: 0.9906 - val_loss: 0.0370 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9906 - loss: 0.0309 - val_accuracy: 0.9916 - val_loss: 0.0339 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9882 - loss: 0.0375 - val_accuracy: 0.9916 - val_loss: 0.0386 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.03172\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9890 - loss: 0.0301 - val_accuracy: 0.9916 - val_loss: 0.0407 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9908 - loss: 0.0292 - val_accuracy: 0.9916 - val_loss: 0.0423 - learning_rate: 1.2500e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9887 - loss: 0.0308 - val_accuracy: 0.9906 - val_loss: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9898 - loss: 0.0290 - val_accuracy: 0.9916 - val_loss: 0.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.03172\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9898 - loss: 0.0290 - val_accuracy: 0.9916 - val_loss: 0.0357 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9895 - loss: 0.0283 - val_accuracy: 0.9916 - val_loss: 0.0386 - learning_rate: 6.2500e-05\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9919 - loss: 0.0244 - val_accuracy: 0.9916 - val_loss: 0.0394 - learning_rate: 6.2500e-05\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9890 - loss: 0.0317 - val_accuracy: 0.9916 - val_loss: 0.0381 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.03172\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9898 - loss: 0.0282 - val_accuracy: 0.9927 - val_loss: 0.0390 - learning_rate: 6.2500e-05\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.03172\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9911 - loss: 0.0233 - val_accuracy: 0.9916 - val_loss: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.03172\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9903 - loss: 0.0242 - val_accuracy: 0.9916 - val_loss: 0.0395 - learning_rate: 3.1250e-05\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.03172\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9914 - loss: 0.0248 - val_accuracy: 0.9916 - val_loss: 0.0386 - learning_rate: 3.1250e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Fold 2 Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\n",
      "[[475   2]\n",
      " [  6 471]]\n",
      "TN=475, FP=2, FN=6, TP=471\n",
      "\n",
      "Fold 2 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9916\n",
      "Precision   : 0.9958  (class 1)\n",
      "Sensitivity : 0.9874  (Recall for class 1)\n",
      "Specificity : 0.9958  (for class 0)\n",
      "F1-score    : 0.9916\n",
      "\n",
      "==========================================================================================\n",
      "Fold 3 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(0.0003, 0.9593) | Train per-electrode std range: [1.000, 1.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_6 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_2 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_7 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_4 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_2 (\u001b[38;5;33mSeparableConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_8 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_5 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,025</span> (35.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,025\u001b[0m (35.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,897</span> (34.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,897\u001b[0m (34.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.67411, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 7s - 57ms/step - accuracy: 0.6753 - loss: 0.5960 - val_accuracy: 0.5273 - val_loss: 0.6741 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67411 to 0.54785, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.8671 - loss: 0.3357 - val_accuracy: 0.6572 - val_loss: 0.5479 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54785 to 0.18502, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9112 - loss: 0.2265 - val_accuracy: 0.9298 - val_loss: 0.1850 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.18502\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9395 - loss: 0.1662 - val_accuracy: 0.9350 - val_loss: 0.1896 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.18502 to 0.05541, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9494 - loss: 0.1394 - val_accuracy: 0.9811 - val_loss: 0.0554 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05541\n",
      "120/120 - 4s - 32ms/step - accuracy: 0.9615 - loss: 0.1080 - val_accuracy: 0.9748 - val_loss: 0.0657 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.05541 to 0.05342, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9623 - loss: 0.0961 - val_accuracy: 0.9853 - val_loss: 0.0534 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.05342 to 0.04150, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 31ms/step - accuracy: 0.9680 - loss: 0.0837 - val_accuracy: 0.9864 - val_loss: 0.0415 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.04150 to 0.03279, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 31ms/step - accuracy: 0.9735 - loss: 0.0776 - val_accuracy: 0.9885 - val_loss: 0.0328 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss improved from 0.03279 to 0.03097, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 33ms/step - accuracy: 0.9748 - loss: 0.0652 - val_accuracy: 0.9895 - val_loss: 0.0310 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.03097\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9814 - loss: 0.0562 - val_accuracy: 0.9906 - val_loss: 0.0333 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.03097 to 0.01960, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9788 - loss: 0.0600 - val_accuracy: 0.9916 - val_loss: 0.0196 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.01960\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9872 - loss: 0.0426 - val_accuracy: 0.9906 - val_loss: 0.0314 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01960\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9798 - loss: 0.0525 - val_accuracy: 0.9864 - val_loss: 0.0535 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.01960 to 0.01900, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9793 - loss: 0.0549 - val_accuracy: 0.9916 - val_loss: 0.0190 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9832 - loss: 0.0455 - val_accuracy: 0.9916 - val_loss: 0.0381 - learning_rate: 1.0000e-03\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9759 - loss: 0.0745 - val_accuracy: 0.9906 - val_loss: 0.0287 - learning_rate: 1.0000e-03\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9775 - loss: 0.0751 - val_accuracy: 0.9864 - val_loss: 0.0566 - learning_rate: 1.0000e-03\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01900\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9817 - loss: 0.0503 - val_accuracy: 0.9916 - val_loss: 0.0327 - learning_rate: 1.0000e-03\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01900\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9887 - loss: 0.0329 - val_accuracy: 0.9906 - val_loss: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9885 - loss: 0.0331 - val_accuracy: 0.9916 - val_loss: 0.0366 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9903 - loss: 0.0347 - val_accuracy: 0.9906 - val_loss: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9893 - loss: 0.0271 - val_accuracy: 0.9937 - val_loss: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01900\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9929 - loss: 0.0213 - val_accuracy: 0.9906 - val_loss: 0.0239 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9932 - loss: 0.0218 - val_accuracy: 0.9927 - val_loss: 0.0208 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9919 - loss: 0.0238 - val_accuracy: 0.9927 - val_loss: 0.0210 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01900\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9911 - loss: 0.0226 - val_accuracy: 0.9927 - val_loss: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01900\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9934 - loss: 0.0205 - val_accuracy: 0.9948 - val_loss: 0.0215 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9893 - loss: 0.0279 - val_accuracy: 0.9937 - val_loss: 0.0226 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01900\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9945 - loss: 0.0203 - val_accuracy: 0.9937 - val_loss: 0.0211 - learning_rate: 1.2500e-04\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Fold 3 Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\n",
      "[[475   2]\n",
      " [  6 471]]\n",
      "TN=475, FP=2, FN=6, TP=471\n",
      "\n",
      "Fold 3 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9916\n",
      "Precision   : 0.9958  (class 1)\n",
      "Sensitivity : 0.9874  (Recall for class 1)\n",
      "Specificity : 0.9958  (for class 0)\n",
      "F1-score    : 0.9916\n",
      "\n",
      "==========================================================================================\n",
      "Fold 4 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(0.0012, 0.9685) | Train per-electrode std range: [1.000, 1.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_9 (\u001b[38;5;33mBatchNormalization\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_3 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_10 (\u001b[38;5;33mBatchNormalization\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_6 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_3 (\u001b[38;5;33mSeparableConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_11 (\u001b[38;5;33mBatchNormalization\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_7 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,025</span> (35.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,025\u001b[0m (35.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,897</span> (34.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,897\u001b[0m (34.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.64069, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 6s - 54ms/step - accuracy: 0.7188 - loss: 0.5745 - val_accuracy: 0.5734 - val_loss: 0.6407 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.64069 to 0.50490, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.8708 - loss: 0.3328 - val_accuracy: 0.7034 - val_loss: 0.5049 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.50490 to 0.17234, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9219 - loss: 0.2161 - val_accuracy: 0.9329 - val_loss: 0.1723 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17234 to 0.09038, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9403 - loss: 0.1663 - val_accuracy: 0.9696 - val_loss: 0.0904 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.09038 to 0.04890, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9505 - loss: 0.1289 - val_accuracy: 0.9822 - val_loss: 0.0489 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.04890 to 0.04197, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9615 - loss: 0.0998 - val_accuracy: 0.9864 - val_loss: 0.0420 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.04197 to 0.02249, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9625 - loss: 0.0917 - val_accuracy: 0.9927 - val_loss: 0.0225 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.02249 to 0.01741, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9651 - loss: 0.0973 - val_accuracy: 0.9958 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01741\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9691 - loss: 0.0812 - val_accuracy: 0.9916 - val_loss: 0.0221 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01741\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9767 - loss: 0.0706 - val_accuracy: 0.9895 - val_loss: 0.0249 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.01741 to 0.01395, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9775 - loss: 0.0591 - val_accuracy: 0.9948 - val_loss: 0.0140 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01395\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9790 - loss: 0.0616 - val_accuracy: 0.9927 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.01395\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9717 - loss: 0.0757 - val_accuracy: 0.9937 - val_loss: 0.0156 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss improved from 0.01395 to 0.00791, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9858 - loss: 0.0420 - val_accuracy: 0.9990 - val_loss: 0.0079 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00791\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9864 - loss: 0.0388 - val_accuracy: 0.9969 - val_loss: 0.0093 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.00791 to 0.00768, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9851 - loss: 0.0402 - val_accuracy: 0.9990 - val_loss: 0.0077 - learning_rate: 1.0000e-03\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.00768 to 0.00730, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9858 - loss: 0.0377 - val_accuracy: 0.9969 - val_loss: 0.0073 - learning_rate: 1.0000e-03\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.00730 to 0.00673, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9885 - loss: 0.0356 - val_accuracy: 0.9979 - val_loss: 0.0067 - learning_rate: 1.0000e-03\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00673\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9843 - loss: 0.0399 - val_accuracy: 0.9979 - val_loss: 0.0068 - learning_rate: 1.0000e-03\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00673\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9893 - loss: 0.0280 - val_accuracy: 0.9969 - val_loss: 0.0080 - learning_rate: 1.0000e-03\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00673\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9898 - loss: 0.0289 - val_accuracy: 0.9969 - val_loss: 0.0076 - learning_rate: 1.0000e-03\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00673\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9914 - loss: 0.0266 - val_accuracy: 0.9916 - val_loss: 0.0397 - learning_rate: 1.0000e-03\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00673 to 0.00406, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9990 - val_loss: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00406 to 0.00377, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9990 - val_loss: 0.0038 - learning_rate: 5.0000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 31ms/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.9990 - val_loss: 0.0040 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 31ms/step - accuracy: 0.9942 - loss: 0.0190 - val_accuracy: 0.9990 - val_loss: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9927 - loss: 0.0216 - val_accuracy: 0.9969 - val_loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9961 - loss: 0.0140 - val_accuracy: 0.9979 - val_loss: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 31ms/step - accuracy: 0.9942 - loss: 0.0153 - val_accuracy: 0.9990 - val_loss: 0.0038 - learning_rate: 2.5000e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00377\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9955 - loss: 0.0117 - val_accuracy: 0.9979 - val_loss: 0.0049 - learning_rate: 2.5000e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00377 to 0.00313, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.9990 - val_loss: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00313\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9937 - loss: 0.0187 - val_accuracy: 0.9990 - val_loss: 0.0038 - learning_rate: 2.5000e-04\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00313\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9934 - loss: 0.0139 - val_accuracy: 0.9990 - val_loss: 0.0042 - learning_rate: 2.5000e-04\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00313\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9971 - loss: 0.0115 - val_accuracy: 0.9990 - val_loss: 0.0038 - learning_rate: 2.5000e-04\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: val_loss improved from 0.00313 to 0.00284, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9945 - loss: 0.0149 - val_accuracy: 0.9990 - val_loss: 0.0028 - learning_rate: 2.5000e-04\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss improved from 0.00284 to 0.00255, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9963 - loss: 0.0150 - val_accuracy: 0.9990 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss improved from 0.00255 to 0.00188, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9990 - val_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00188\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9963 - loss: 0.0085 - val_accuracy: 0.9990 - val_loss: 0.0025 - learning_rate: 2.5000e-04\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: val_loss improved from 0.00188 to 0.00188, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9990 - val_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9974 - loss: 0.0075 - val_accuracy: 0.9990 - val_loss: 0.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9971 - loss: 0.0070 - val_accuracy: 0.9990 - val_loss: 0.0028 - learning_rate: 1.2500e-04\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9955 - loss: 0.0123 - val_accuracy: 0.9990 - val_loss: 0.0027 - learning_rate: 1.2500e-04\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9990 - val_loss: 0.0030 - learning_rate: 1.2500e-04\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9958 - loss: 0.0105 - val_accuracy: 0.9990 - val_loss: 0.0038 - learning_rate: 1.2500e-04\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00188\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9971 - loss: 0.0070 - val_accuracy: 0.9979 - val_loss: 0.0042 - learning_rate: 6.2500e-05\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00188\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9979 - val_loss: 0.0035 - learning_rate: 6.2500e-05\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.9990 - val_loss: 0.0031 - learning_rate: 6.2500e-05\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9958 - loss: 0.0102 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9958 - loss: 0.0093 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9971 - loss: 0.0073 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00188\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9990 - val_loss: 0.0023 - learning_rate: 3.1250e-05\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00188\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9950 - loss: 0.0120 - val_accuracy: 0.9990 - val_loss: 0.0022 - learning_rate: 3.1250e-05\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00188\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Fold 4 Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\n",
      "[[477   0]\n",
      " [  1 476]]\n",
      "TN=477, FP=0, FN=1, TP=476\n",
      "\n",
      "Fold 4 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9990\n",
      "Precision   : 1.0000  (class 1)\n",
      "Sensitivity : 0.9979  (Recall for class 1)\n",
      "Specificity : 1.0000  (for class 0)\n",
      "F1-score    : 0.9990\n",
      "\n",
      "==========================================================================================\n",
      "Fold 5 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(-0.0000, 1.0000) | Val(mean,std)=(-0.0002, 1.0114) | Train per-electrode std range: [1.000, 1.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_12 (\u001b[38;5;33mBatchNormalization\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ depthwise_conv2d_4 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_13 (\u001b[38;5;33mBatchNormalization\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_8 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ separable_conv2d_4 (\u001b[38;5;33mSeparableConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                 \u001b[38;5;34m1,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ batch_normalization_14 (\u001b[38;5;33mBatchNormalization\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ average_pooling2d_9 (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                       │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,025</span> (35.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,025\u001b[0m (35.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,897</span> (34.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,897\u001b[0m (34.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.61465, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 7s - 55ms/step - accuracy: 0.7120 - loss: 0.5549 - val_accuracy: 0.6300 - val_loss: 0.6147 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61465 to 0.35085, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.8834 - loss: 0.3070 - val_accuracy: 0.8333 - val_loss: 0.3509 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.35085 to 0.11152, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9321 - loss: 0.1870 - val_accuracy: 0.9602 - val_loss: 0.1115 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.11152 to 0.08250, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9468 - loss: 0.1448 - val_accuracy: 0.9843 - val_loss: 0.0825 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.08250 to 0.06090, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9541 - loss: 0.1144 - val_accuracy: 0.9874 - val_loss: 0.0609 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.06090 to 0.04615, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9623 - loss: 0.1037 - val_accuracy: 0.9864 - val_loss: 0.0462 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.04615\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9693 - loss: 0.0864 - val_accuracy: 0.9895 - val_loss: 0.0514 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.04615 to 0.04341, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9725 - loss: 0.0799 - val_accuracy: 0.9895 - val_loss: 0.0434 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.04341 to 0.03568, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9691 - loss: 0.0825 - val_accuracy: 0.9906 - val_loss: 0.0357 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss improved from 0.03568 to 0.03030, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 29ms/step - accuracy: 0.9733 - loss: 0.0711 - val_accuracy: 0.9916 - val_loss: 0.0303 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.03030 to 0.02676, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9759 - loss: 0.0590 - val_accuracy: 0.9948 - val_loss: 0.0268 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.02676\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9803 - loss: 0.0563 - val_accuracy: 0.9948 - val_loss: 0.0303 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.02676\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9764 - loss: 0.0668 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss improved from 0.02676 to 0.02095, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9775 - loss: 0.0621 - val_accuracy: 0.9927 - val_loss: 0.0209 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.02095\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9767 - loss: 0.0629 - val_accuracy: 0.9927 - val_loss: 0.0277 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.02095 to 0.01981, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 3s - 28ms/step - accuracy: 0.9817 - loss: 0.0556 - val_accuracy: 0.9927 - val_loss: 0.0198 - learning_rate: 1.0000e-03\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.01981\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9840 - loss: 0.0462 - val_accuracy: 0.9927 - val_loss: 0.0215 - learning_rate: 1.0000e-03\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01981\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9869 - loss: 0.0391 - val_accuracy: 0.9906 - val_loss: 0.0280 - learning_rate: 1.0000e-03\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01981\n",
      "120/120 - 4s - 37ms/step - accuracy: 0.9885 - loss: 0.0377 - val_accuracy: 0.9948 - val_loss: 0.0214 - learning_rate: 1.0000e-03\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss improved from 0.01981 to 0.01784, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 31ms/step - accuracy: 0.9898 - loss: 0.0316 - val_accuracy: 0.9958 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01784\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9830 - loss: 0.0428 - val_accuracy: 0.9927 - val_loss: 0.0287 - learning_rate: 1.0000e-03\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01784\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9848 - loss: 0.0382 - val_accuracy: 0.9937 - val_loss: 0.0192 - learning_rate: 1.0000e-03\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01784\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9885 - loss: 0.0353 - val_accuracy: 0.9958 - val_loss: 0.0189 - learning_rate: 1.0000e-03\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01784\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9906 - loss: 0.0287 - val_accuracy: 0.9969 - val_loss: 0.0202 - learning_rate: 1.0000e-03\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01784\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9945 - loss: 0.0210 - val_accuracy: 0.9958 - val_loss: 0.0186 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss improved from 0.01784 to 0.01722, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 29ms/step - accuracy: 0.9937 - loss: 0.0169 - val_accuracy: 0.9958 - val_loss: 0.0172 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01722\n",
      "120/120 - 4s - 32ms/step - accuracy: 0.9950 - loss: 0.0183 - val_accuracy: 0.9958 - val_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01722\n",
      "120/120 - 4s - 35ms/step - accuracy: 0.9934 - loss: 0.0220 - val_accuracy: 0.9958 - val_loss: 0.0216 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01722\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9948 - loss: 0.0159 - val_accuracy: 0.9969 - val_loss: 0.0187 - learning_rate: 5.0000e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01722\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9929 - loss: 0.0201 - val_accuracy: 0.9958 - val_loss: 0.0229 - learning_rate: 5.0000e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.01722\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9945 - loss: 0.0170 - val_accuracy: 0.9969 - val_loss: 0.0182 - learning_rate: 2.5000e-04\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.01722\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9921 - loss: 0.0207 - val_accuracy: 0.9969 - val_loss: 0.0191 - learning_rate: 2.5000e-04\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.01722\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9963 - loss: 0.0137 - val_accuracy: 0.9969 - val_loss: 0.0173 - learning_rate: 2.5000e-04\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.01722\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9969 - val_loss: 0.0174 - learning_rate: 2.5000e-04\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.01722\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9974 - loss: 0.0106 - val_accuracy: 0.9969 - val_loss: 0.0184 - learning_rate: 1.2500e-04\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss improved from 0.01722 to 0.01457, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 4s - 30ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.9969 - val_loss: 0.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.9969 - val_loss: 0.0168 - learning_rate: 1.2500e-04\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.01457\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9963 - loss: 0.0123 - val_accuracy: 0.9969 - val_loss: 0.0191 - learning_rate: 1.2500e-04\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.01457\n",
      "120/120 - 3s - 28ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.9969 - val_loss: 0.0196 - learning_rate: 1.2500e-04\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9966 - loss: 0.0078 - val_accuracy: 0.9969 - val_loss: 0.0175 - learning_rate: 1.2500e-04\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 31ms/step - accuracy: 0.9969 - loss: 0.0108 - val_accuracy: 0.9969 - val_loss: 0.0170 - learning_rate: 6.2500e-05\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.01457\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9969 - loss: 0.0108 - val_accuracy: 0.9969 - val_loss: 0.0168 - learning_rate: 6.2500e-05\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.01457\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9976 - loss: 0.0089 - val_accuracy: 0.9969 - val_loss: 0.0169 - learning_rate: 6.2500e-05\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.9969 - val_loss: 0.0167 - learning_rate: 6.2500e-05\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9969 - val_loss: 0.0167 - learning_rate: 3.1250e-05\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9958 - loss: 0.0115 - val_accuracy: 0.9969 - val_loss: 0.0170 - learning_rate: 3.1250e-05\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9971 - loss: 0.0072 - val_accuracy: 0.9969 - val_loss: 0.0173 - learning_rate: 3.1250e-05\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 29ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.9969 - val_loss: 0.0172 - learning_rate: 3.1250e-05\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.01457\n",
      "120/120 - 3s - 29ms/step - accuracy: 0.9979 - loss: 0.0083 - val_accuracy: 0.9969 - val_loss: 0.0174 - learning_rate: 1.5625e-05\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 32ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9969 - val_loss: 0.0170 - learning_rate: 1.5625e-05\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.01457\n",
      "120/120 - 4s - 30ms/step - accuracy: 0.9958 - loss: 0.0118 - val_accuracy: 0.9969 - val_loss: 0.0171 - learning_rate: 1.5625e-05\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Fold 5 Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\n",
      "[[475   2]\n",
      " [  1 476]]\n",
      "TN=475, FP=2, FN=1, TP=476\n",
      "\n",
      "Fold 5 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9969\n",
      "Precision   : 0.9958  (class 1)\n",
      "Sensitivity : 0.9979  (Recall for class 1)\n",
      "Specificity : 0.9958  (for class 0)\n",
      "F1-score    : 0.9969\n",
      "\n",
      "=== Per-Fold Metrics Summary ===\n",
      "Fold 1: Acc=0.9990, Prec=1.0000, Sens=0.9979, Spec=1.0000, F1=0.9990 | TN=477 FP=0 FN=1 TP=476\n",
      "Fold 2: Acc=0.9916, Prec=0.9958, Sens=0.9874, Spec=0.9958, F1=0.9916 | TN=475 FP=2 FN=6 TP=471\n",
      "Fold 3: Acc=0.9916, Prec=0.9958, Sens=0.9874, Spec=0.9958, F1=0.9916 | TN=475 FP=2 FN=6 TP=471\n",
      "Fold 4: Acc=0.9990, Prec=1.0000, Sens=0.9979, Spec=1.0000, F1=0.9990 | TN=477 FP=0 FN=1 TP=476\n",
      "Fold 5: Acc=0.9969, Prec=0.9958, Sens=0.9979, Spec=0.9958, F1=0.9969 | TN=475 FP=2 FN=1 TP=476\n",
      "\n",
      "=== Mean ± Std over 5 folds ===\n",
      "Accuracy    : 0.9956 ± 0.0033\n",
      "Precision   : 0.9975 ± 0.0021\n",
      "Sensitivity : 0.9937 ± 0.0051\n",
      "Specificity : 0.9975 ± 0.0021\n",
      "F1-score    : 0.9956 ± 0.0034\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: 5-fold CV with confusion matrix + metrics using EEGNet =====\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assumptions:\n",
    "# - X has shape (n_samples, n_channels, n_times, 1)\n",
    "# - y has shape (n_samples,) with binary labels {0,1}\n",
    "# - normalize_per_fold(X_train, X_val) is defined elsewhere in your notebook\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "per_fold_metrics = []\n",
    "histories = []\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    fold += 1\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"Fold {fold} — Train/Val split\")\n",
    "    print(\"Train idx:\", train_idx.shape, \"Val idx:\", val_idx.shape)\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    print(\"X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "    print(\"X_val  :\", X_val.shape,   \"| y_val  :\", y_val.shape)\n",
    "\n",
    "    # ----- Per-fold normalization (train-only stats) -----\n",
    "    X_train, X_val = normalize_per_fold(X_train, X_val)\n",
    "\n",
    "    # Sanity checks\n",
    "    train_global_mean = float(np.mean(X_train))\n",
    "    train_global_std  = float(np.std(X_train))\n",
    "    val_global_mean   = float(np.mean(X_val))\n",
    "    val_global_std    = float(np.std(X_val))\n",
    "    # If electrodes dimension is axis=1 (n_channels), std over (samples, time, features)\n",
    "    train_per_elec_std = np.std(X_train, axis=(0, 2, 3))\n",
    "\n",
    "    print(\n",
    "        \"Normalization check — \"\n",
    "        f\"Train(mean,std)=({train_global_mean:.4f}, {train_global_std:.4f}) | \"\n",
    "        f\"Val(mean,std)=({val_global_mean:.4f}, {val_global_std:.4f}) | \"\n",
    "        f\"Train per-electrode std range: [{train_per_elec_std.min():.3f}, {train_per_elec_std.max():.3f}]\"\n",
    "    )\n",
    "\n",
    "    # ----- Build model with per-fold input shape -----\n",
    "    input_shape = X_train.shape[1:]  # (n_channels, n_times, 1)\n",
    "    model = create_cnn_model(input_shape=input_shape, dropout_rate=0.5, num_classes=1, lr=1e-3)\n",
    "    print(model.summary(line_length=120))\n",
    "\n",
    "    callbacks = make_callbacks(fold)\n",
    "\n",
    "    print(\"Training with EarlyStopping...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    histories.append(history.history)\n",
    "\n",
    "    print(\"Predicting on validation fold...\")\n",
    "    y_prob = model.predict(X_val, batch_size=BATCH_SIZE).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    # ----- Confusion Matrix & Metrics -----\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Confusion Matrix (rows=true, cols=pred) [0=Class0, 1=Class1]:\")\n",
    "    print(cm)\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "\n",
    "    acc  = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    sens = recall_score(y_val, y_pred,    pos_label=1, zero_division=0)\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    f1   = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Metrics (threshold=0.5):\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {prec:.4f}  (class 1)\")\n",
    "    print(f\"Sensitivity : {sens:.4f}  (Recall for class 1)\")\n",
    "    print(f\"Specificity : {spec:.4f}  (for class 0)\")\n",
    "    print(f\"F1-score    : {f1:.4f}\")\n",
    "\n",
    "    per_fold_metrics.append({\n",
    "        \"fold\": fold, \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
    "        \"accuracy\": float(acc), \"precision\": float(prec),\n",
    "        \"sensitivity\": float(sens), \"specificity\": float(spec), \"f1\": float(f1)\n",
    "    })\n",
    "\n",
    "# ----- Per-fold summary -----\n",
    "print(\"\\n=== Per-Fold Metrics Summary ===\")\n",
    "for m in per_fold_metrics:\n",
    "    print(f\"Fold {m['fold']}: \"\n",
    "          f\"Acc={m['accuracy']:.4f}, \"\n",
    "          f\"Prec={m['precision']:.4f}, \"\n",
    "          f\"Sens={m['sensitivity']:.4f}, \"\n",
    "          f\"Spec={m['specificity']:.4f}, \"\n",
    "          f\"F1={m['f1']:.4f} | \"\n",
    "          f\"TN={m['tn']} FP={m['fp']} FN={m['fn']} TP={m['tp']}\")\n",
    "\n",
    "# ----- Mean ± Std across folds -----\n",
    "accs  = [m[\"accuracy\"]    for m in per_fold_metrics]\n",
    "precs = [m[\"precision\"]   for m in per_fold_metrics]\n",
    "senss = [m[\"sensitivity\"] for m in per_fold_metrics]\n",
    "specs = [m[\"specificity\"] for m in per_fold_metrics]\n",
    "f1s   = [m[\"f1\"]          for m in per_fold_metrics]\n",
    "\n",
    "print(\"\\n=== Mean ± Std over\", N_SPLITS, \"folds ===\")\n",
    "print(f\"Accuracy    : {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision   : {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Sensitivity : {np.mean(senss):.4f} ± {np.std(senss):.4f}\")\n",
    "print(f\"Specificity : {np.mean(specs):.4f} ± {np.std(specs):.4f}\")\n",
    "print(f\"F1-score    : {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abc00d-73b3-4d50-b24b-97115e3678cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
