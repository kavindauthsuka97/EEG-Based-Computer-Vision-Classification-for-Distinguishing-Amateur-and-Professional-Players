{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d3cb4b-2b03-4283-87bf-b807e7c10d23",
   "metadata": {},
   "source": [
    "step 1- Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac08b3e9-3cf8-4469-bf1e-f8a3a6884e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 1: Imports, seeds, and GPU setup =====\n",
    "\n",
    "# Standard libraries\n",
    "import os, random                              # OS utilities and reproducibility\n",
    "import numpy as np                             # Numerical arrays\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf                        # Main DL framework\n",
    "\n",
    "# Keras layers & utilities\n",
    "from tensorflow.keras.layers import (Input, SeparableConv2D, DepthwiseConv2D, BatchNormalization,\n",
    "                                     Activation, AveragePooling2D, Dropout, Dense, Add, Lambda,\n",
    "                                     GlobalAveragePooling2D, GlobalAveragePooling1D,\n",
    "                                     MultiHeadAttention, Reshape, LayerNormalization, Conv2D)\n",
    "from tensorflow.keras.models import Model      # Functional model API\n",
    "from tensorflow.keras.optimizers import Adam   # Optimizer\n",
    "from tensorflow.keras.losses import BinaryCrossentropy  # Binary classification loss\n",
    "from tensorflow.keras.metrics import Accuracy  # Accuracy metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # Training callbacks\n",
    "from tensorflow.keras import backend as K      # Keras backend for static shape queries\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import StratifiedKFold                  # Stratified 5-fold CV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score  # Metrics\n",
    "\n",
    "# Plotting (optional)\n",
    "import matplotlib.pyplot as plt               # For charts (optional)\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42                                     # Fixed seed\n",
    "np.random.seed(SEED)                          # Seed NumPy\n",
    "tf.random.set_seed(SEED)                      # Seed TensorFlow\n",
    "random.seed(SEED)                             # Seed Python\n",
    "\n",
    "# Optional: make TensorFlow gentle with GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU') # Detect GPUs\n",
    "print(\"TensorFlow:\", tf.__version__)          # Show TF version\n",
    "print(\"GPUs:\", gpus)                          # Show detected GPUs\n",
    "if gpus:                                      # If GPU(s) are present\n",
    "    for g in gpus:                            # Iterate each GPU\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(g, True)  # Enable memory growth\n",
    "        except Exception as e:\n",
    "            print(\"GPU memory growth not set:\", e)             # Warn if not possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07e80a-cf10-4e44-8609-3a8acc6c6a34",
   "metadata": {},
   "source": [
    "Step 2- Load arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f8364b-fe04-40e2-b139-7275af0eaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "Loaded.\n",
      "Raw X shape: (4770, 14, 200) | dtype: float64\n",
      "Raw y shape: (4770,) | dtype: int64\n",
      "y squeezed shape: (4770,) | unique labels: [0 1]\n",
      "X after adding channel dim: (4770, 14, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 2: Load the arrays in the given path (no normalization) =====\n",
    "\n",
    "# Exact Windows paths you provided (raw strings to avoid backslash escapes)\n",
    "eeg_path    = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_pp.npy\"\n",
    "labels_path = r\"C:\\Self Learning\\Research Papers\\UOW Research Papers\\eSport Players with EEG Data\\EEG Data\\final eeg data\\final_eeg_labels.npy\"\n",
    "\n",
    "print(\"Loading EEG data...\")                 # Status print\n",
    "X = np.load(eeg_path)                        # Load EEG data, expected shape (N, 14, 200)\n",
    "y = np.load(labels_path)                     # Load labels, expected shape (N,) or (N,1)\n",
    "print(\"Loaded.\")                             # Confirm loaded\n",
    "\n",
    "print(\"Raw X shape:\", X.shape, \"| dtype:\", X.dtype)  # Inspect EEG tensor\n",
    "print(\"Raw y shape:\", y.shape, \"| dtype:\", y.dtype)  # Inspect labels\n",
    "\n",
    "y = np.squeeze(y).astype(int)                # Ensure labels are 1D int array\n",
    "print(\"y squeezed shape:\", y.shape, \"| unique labels:\", np.unique(y))  # Show label distribution\n",
    "\n",
    "# Sanity checks on shapes and labels\n",
    "assert X.ndim == 3, f\"Expected X to be (N,14,200). Got {X.shape}\"      # Check rank\n",
    "assert X.shape[1] == 14 and X.shape[2] == 200, \"Expected 14 electrodes and 200 samples per segment.\"  # Check dims\n",
    "assert set(np.unique(y)).issubset({0,1}), \"Labels must be {0,1}.\"      # Binary check\n",
    "\n",
    "# Add channel dimension for Keras Conv2D: (N, 14, 200, 1)\n",
    "X = X[..., np.newaxis]                         # Append channel dim\n",
    "print(\"X after adding channel dim:\", X.shape)  # Verify final input shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1573ae-b7d7-46c2-b447-948c63bd620b",
   "metadata": {},
   "source": [
    "Step 3: Normalising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da717924-cc93-47c0-b426-a429d850f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 3: Normalization helper (per-fold; compute stats on train only) =====\n",
    "\n",
    "def normalize_per_fold(X_train, X_val, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Normalizes X_train and X_val using mean/std computed from X_train only.\n",
    "    Broadcasting shape is (1, 14, 1, 1), i.e., per-electrode normalization.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute mean & std from the training set only\n",
    "    train_mean = np.mean(X_train, axis=(0, 2, 3), keepdims=True)   # -> (1, 14, 1, 1)\n",
    "    train_std  = np.std( X_train, axis=(0, 2, 3), keepdims=True)   # -> (1, 14, 1, 1)\n",
    "\n",
    "    # Safety: avoid division by (near) zero\n",
    "    train_std = np.where(train_std < eps, 1.0, train_std)\n",
    "\n",
    "    # Step 2: Apply normalization using training mean & std\n",
    "    X_train_norm = ((X_train - train_mean) / train_std).astype(np.float32)\n",
    "    X_val_norm   = ((X_val   - train_mean) / train_std).astype(np.float32)\n",
    "\n",
    "    print(\"Per-fold normalization done.\",\n",
    "          \"train_mean shape:\", train_mean.shape, \"train_std shape:\", train_std.shape)\n",
    "\n",
    "    return X_train_norm, X_val_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2af7b-1685-4573-b263-604591d7918e",
   "metadata": {},
   "source": [
    "Step 4: Prepare 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7727ac88-2626-48a3-ad00-30da848d423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared StratifiedKFold with 5 splits.\n",
      "Total samples: 4770\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 4: Prepare the data to perform 5-fold cross validation =====\n",
    "\n",
    "N_SPLITS = 5                                   # Number of CV folds\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS,       # Stratified (preserves class ratios)\n",
    "                      shuffle=True,            # Shuffle before splitting\n",
    "                      random_state=SEED)       # Reproducible splits\n",
    "\n",
    "print(f\"Prepared StratifiedKFold with {N_SPLITS} splits.\")  # Status\n",
    "print(\"Total samples:\", X.shape[0])                         # Dataset size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e50d7-72cd-41ee-94b4-207be8e301f7",
   "metadata": {},
   "source": [
    "Step 5: Model, compile, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82374f63-b924-4a09-837f-d6dbbbf5c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 5: Define AFNet (your code, only shape edits + Keras-safe ops) =====\n",
    "\n",
    "def SpatialAttention(x):\n",
    "    \"\"\"Spatial attention to weight electrodes; uses Keras Reshape/Multiply (no raw tf ops on KerasTensors).\"\"\"\n",
    "    num_electrodes = K.int_shape(x)[1]                        # Static electrode count (14)\n",
    "    attn = GlobalAveragePooling2D()(x)                        # Global pool -> (batch, channels)\n",
    "    attn = Dense(64, activation='relu')(attn)                 # Dense to learn attention features\n",
    "    attn = Dense(num_electrodes, activation='sigmoid')(attn)  # One weight per electrode\n",
    "    attn = Reshape((num_electrodes, 1, 1))(attn)              # Reshape for broadcast across time & channels\n",
    "    x = tf.keras.layers.Multiply()([x, attn])                 # Apply attention weights\n",
    "    return x                                                  # Return attended feature maps\n",
    "\n",
    "def TransformerBlock(x, num_heads=4, key_dim=64, ff_dim=128, dropout_rate=0.1):\n",
    "    \"\"\"Transformer encoder block: MHA + FFN with residuals and layer norms.\"\"\"\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)  # Self-attention\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)                               # Dropout\n",
    "    x = Add()([x, attn_output])                                                   # Residual\n",
    "    x = LayerNormalization()(x)                                                   # LayerNorm\n",
    "\n",
    "    ff = Dense(ff_dim, activation='relu')(x)                                      # Feed-forward (expand)\n",
    "    ff = Dropout(dropout_rate)(ff)                                                # Dropout\n",
    "    ff = Dense(x.shape[-1])(ff)                                                   # Project back\n",
    "    x = Add()([x, ff])                                                            # Residual\n",
    "    x = LayerNormalization()(x)                                                   # LayerNorm\n",
    "    return x                                                                      # Return block output\n",
    "\n",
    "def EEGNet_SpatialTransformer(input_shape=(14, 200, 1), dropout_rate=0.5, num_heads=4, ff_dim=128):\n",
    "    \"\"\"AFNet adapted for (14,200,1); keeps your structure, minimal shape handling for residual add.\"\"\"\n",
    "    print(\"Building model with input_shape:\", input_shape)                         # Trace\n",
    "\n",
    "    inputs = Input(shape=input_shape)                                              # Input tensor\n",
    "\n",
    "    # Depthwise Separable Convolution (temporal)\n",
    "    x = SeparableConv2D(32, (1, 5), padding='same', use_bias=False)(inputs)       # First sep conv\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After sepconv1:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Spatial Attention\n",
    "    x = SpatialAttention(x)                                                        # Attention over electrodes\n",
    "    print(\"After SpatialAttention:\", x.shape)                                      # Shape trace\n",
    "\n",
    "    # Depthwise Spatial Convolution across electrodes (change 61->14)\n",
    "    x = DepthwiseConv2D((14, 1), use_bias=False, depth_multiplier=2, padding='valid')(x)  # Collapse electrode dim\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After depthwise spatial:\", x.shape)                                     # Shape trace (electrode dim -> 1)\n",
    "\n",
    "    # Residual branch from inputs via the same first sepconv path (to get 32 channels & same HxW)\n",
    "    res = SeparableConv2D(32, (1, 5), padding='same', use_bias=False)(inputs)      # Residual features (14x200x32)\n",
    "    res = BatchNormalization()(res)                                                # BN\n",
    "    res = Activation('relu')(res)                                                  # ReLU\n",
    "    print(\"Residual branch shape:\", res.shape)                                     # Shape trace\n",
    "\n",
    "    # Project x back to 32 channels so we can add with residual\n",
    "    x = Conv2D(32, (1,1), padding='same', use_bias=False)(x)                       # 1x1 to 32 channels\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After 1x1 proj to 32:\", x.shape)                                        # Shape trace (1x200x32)\n",
    "\n",
    "    # Tile the electrode axis from 1 -> 14 to match residual spatial dims for Add()\n",
    "    x = Lambda(lambda t: tf.repeat(t, repeats=input_shape[0], axis=1))(x)          # Repeat along axis=1\n",
    "    print(\"After tiling to electrodes=14:\", x.shape)                                # Shape trace (14x200x32)\n",
    "\n",
    "    # Add residual and continue\n",
    "    x = Add()([x, res])                                                            # Residual add\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    print(\"After residual add:\", x.shape)                                          # Shape trace\n",
    "\n",
    "    # First Average Pooling (temporal downsampling: 200 -> 50)\n",
    "    x = AveragePooling2D((1, 4))(x)                                                # Pool time axis\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    print(\"After avgpool1:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Second separable conv block\n",
    "    x = SeparableConv2D(64, (1, 3), padding='same', use_bias=False)(x)             # More features\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Activation('relu')(x)                                                      # ReLU\n",
    "    print(\"After sepconv2:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Second Average Pooling (temporal downsampling: ~50 -> ~12/13)\n",
    "    x = AveragePooling2D((1, 4))(x)                                                # Pool time again\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    print(\"After avgpool2:\", x.shape)                                              # Shape trace\n",
    "\n",
    "    # Transformer over electrodes (tokens = 14, features = T' * 64)\n",
    "    x_shape = K.int_shape(x)                                                       # Static shape\n",
    "    seq_len = x_shape[1]                                                           # Electrode tokens (14)\n",
    "    feat_dim = x_shape[2] * x_shape[3]                                             # Feature dim per token\n",
    "    x = Reshape((seq_len, feat_dim))(x)                                            # (batch, 14, T'*64)\n",
    "    print(\"Before Transformer, reshaped to:\", x.shape)                              # Trace shape\n",
    "\n",
    "    x = TransformerBlock(x, num_heads=num_heads, key_dim=64, ff_dim=ff_dim, dropout_rate=0.1)  # Transformer\n",
    "\n",
    "    # Classifier head\n",
    "    x = GlobalAveragePooling1D()(x)                                                # Pool across tokens\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    print(\"After GAP1D:\", x.shape)                                                 # Shape trace\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)                                           # Dense layer\n",
    "    x = BatchNormalization()(x)                                                    # BN\n",
    "    x = Dropout(dropout_rate)(x)                                                   # Dropout\n",
    "    outputs = Dense(1, activation='sigmoid')(x)                                    # Sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs, outputs)                                                 # Build model\n",
    "    return model                                                                   # Return uncompiled model\n",
    "\n",
    "\n",
    "# ===== Helpers: compile model and callbacks =====\n",
    "\n",
    "def compile_model():\n",
    "    \"\"\"Create and compile a fresh AFNet model instance.\"\"\"\n",
    "    model = EEGNet_SpatialTransformer(input_shape=(14, 200, 1))             # Build with correct input shape\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),                       # Adam optimizer (lr=1e-3)\n",
    "                  loss=BinaryCrossentropy(),                                # Binary cross-entropy loss\n",
    "                  metrics=[Accuracy()])                                     # Track Accuracy metric\n",
    "    print(model.summary(line_length=120))                                   # Print model summary\n",
    "    return model                                                            # Return compiled model\n",
    "\n",
    "def make_callbacks(fold_idx):\n",
    "    \"\"\"Construct callbacks for a given fold: EarlyStopping + ReduceLROnPlateau + ModelCheckpoint(.h5).\"\"\"\n",
    "    print(f\"Setting up callbacks for fold {fold_idx}...\")                   # Status print\n",
    "\n",
    "    es = EarlyStopping(                                                     # Early stopping\n",
    "        monitor='val_loss',                                                 # Monitor validation loss\n",
    "        patience=15,                                                        # Wait 15 epochs without improvement\n",
    "        restore_best_weights=True,                                          # Restore best weights\n",
    "        verbose=1                                                           # Verbose messages\n",
    "    )\n",
    "\n",
    "    rlrop = ReduceLROnPlateau(                                              # Reduce LR on plateau\n",
    "        monitor='val_loss',                                                 # Monitor validation loss\n",
    "        factor=0.5,                                                         # Halve the LR\n",
    "        patience=4,                                                         # After 4 stagnant epochs\n",
    "        min_lr=1e-6,                                                        # Do not go below 1e-6\n",
    "        verbose=1                                                           # Verbose messages\n",
    "    )\n",
    "\n",
    "    ckpt_path = f\"best_fold_{fold_idx}.h5\"                                  # Save best model as .h5 (HDF5)\n",
    "    ckpt = ModelCheckpoint(                                                 # Checkpoint callback\n",
    "        filepath=ckpt_path,                                                 # Output file path\n",
    "        monitor='val_loss',                                                 # Select best by val_loss\n",
    "        save_best_only=True,                                                # Only save when improved\n",
    "        verbose=1                                                           # Verbose messages\n",
    "        # Note: .h5 requires h5py installed; if missing, run: pip install h5py\n",
    "    )\n",
    "\n",
    "    return [es, rlrop, ckpt]                                                # Return callback list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f00bd69-f2b6-46ad-bbdf-8ef39459547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Fold 1 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(-0.0000, 1.0000) | Val(mean,std)=(-0.0004, 1.0616) | Train per-electrode std range: [1.000, 1.000]\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "WARNING:tensorflow:From C:\\Users\\kuwad\\.conda\\envs\\DL\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
       "│                                   │                              │                   │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             \n",
       "│                                   │                              │                   │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],\n",
       "│                                   │                              │                   │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d[\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
       "│                                   │                              │                   │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             \n",
       "│                                   │                              │                   │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],\n",
       "│                                   │                              │                   │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d[\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 1...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 4.63251, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 240ms/step - accuracy: 2.6205e-04 - loss: 0.3513 - val_accuracy: 0.0000e+00 - val_loss: 4.6325 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 4.63251 to 3.46720, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 2.6205e-04 - loss: 0.0739 - val_accuracy: 0.0000e+00 - val_loss: 3.4672 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 3.46720 to 0.26876, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 173ms/step - accuracy: 0.0018 - loss: 0.0666 - val_accuracy: 0.0000e+00 - val_loss: 0.2688 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.26876 to 0.07779, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 172ms/step - accuracy: 0.0034 - loss: 0.0505 - val_accuracy: 0.0000e+00 - val_loss: 0.0778 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.07779 to 0.03942, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 176ms/step - accuracy: 0.0066 - loss: 0.0414 - val_accuracy: 0.0031 - val_loss: 0.0394 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.03942 to 0.02676, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0055 - loss: 0.0360 - val_accuracy: 0.0409 - val_loss: 0.0268 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.02676\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0100 - loss: 0.0370 - val_accuracy: 0.1080 - val_loss: 0.1460 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.02676\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0092 - loss: 0.0542 - val_accuracy: 0.1237 - val_loss: 0.6756 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.02676\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0034 - loss: 0.0312 - val_accuracy: 0.0314 - val_loss: 0.0276 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.02676\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0055 - loss: 0.0218 - val_accuracy: 0.2966 - val_loss: 0.3356 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.02676 to 0.00910, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 192ms/step - accuracy: 0.0055 - loss: 0.0139 - val_accuracy: 0.1730 - val_loss: 0.0091 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.00910 to 0.00704, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 194ms/step - accuracy: 0.0089 - loss: 0.0156 - val_accuracy: 0.1006 - val_loss: 0.0070 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00704\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0110 - loss: 0.0082 - val_accuracy: 0.1216 - val_loss: 0.0082 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00704\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0131 - loss: 0.0069 - val_accuracy: 0.2778 - val_loss: 0.0223 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00704 to 0.00542, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0170 - loss: 0.0113 - val_accuracy: 0.0168 - val_loss: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00542\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0168 - loss: 0.0059 - val_accuracy: 0.1730 - val_loss: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00542\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0210 - loss: 0.0121 - val_accuracy: 0.1918 - val_loss: 0.0277 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00542\n",
      "120/120 - 23s - 190ms/step - accuracy: 0.0191 - loss: 0.0165 - val_accuracy: 0.0828 - val_loss: 0.0070 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00542\n",
      "120/120 - 23s - 188ms/step - accuracy: 0.0218 - loss: 0.0056 - val_accuracy: 0.2505 - val_loss: 0.0085 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss improved from 0.00542 to 0.00122, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 24s - 198ms/step - accuracy: 0.0267 - loss: 0.0041 - val_accuracy: 0.1415 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00122\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0273 - loss: 0.0022 - val_accuracy: 0.2411 - val_loss: 0.0069 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00122\n",
      "120/120 - 23s - 189ms/step - accuracy: 0.0280 - loss: 0.0026 - val_accuracy: 0.2180 - val_loss: 0.0034 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00122\n",
      "120/120 - 24s - 198ms/step - accuracy: 0.0304 - loss: 0.0020 - val_accuracy: 0.1792 - val_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00122\n",
      "120/120 - 23s - 188ms/step - accuracy: 0.0380 - loss: 0.0026 - val_accuracy: 0.2505 - val_loss: 0.0048 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00122\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0335 - loss: 0.0015 - val_accuracy: 0.2579 - val_loss: 0.0045 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00122\n",
      "120/120 - 22s - 183ms/step - accuracy: 0.0401 - loss: 0.0019 - val_accuracy: 0.2180 - val_loss: 0.0060 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss improved from 0.00122 to 0.00070, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - accuracy: 0.0388 - loss: 0.0020 - val_accuracy: 0.1300 - val_loss: 7.0156e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss improved from 0.00070 to 0.00059, saving model to best_fold_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0398 - loss: 0.0016 - val_accuracy: 0.2149 - val_loss: 5.9034e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00059\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0398 - loss: 9.2885e-04 - val_accuracy: 0.2044 - val_loss: 8.6190e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00059\n",
      "120/120 - 23s - 189ms/step - accuracy: 0.0422 - loss: 8.5085e-04 - val_accuracy: 0.2191 - val_loss: 9.7550e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0516 - loss: 6.8083e-04 - val_accuracy: 0.2233 - val_loss: 0.0014 - learning_rate: 1.2500e-04\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00059\n",
      "120/120 - 23s - 191ms/step - accuracy: 0.0461 - loss: 5.5203e-04 - val_accuracy: 0.2138 - val_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00059\n",
      "120/120 - 23s - 194ms/step - accuracy: 0.0456 - loss: 8.1280e-04 - val_accuracy: 0.2201 - val_loss: 0.0021 - learning_rate: 6.2500e-05\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0490 - loss: 8.2667e-04 - val_accuracy: 0.2044 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0550 - loss: 0.0013 - val_accuracy: 0.2002 - val_loss: 0.0021 - learning_rate: 6.2500e-05\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00059\n",
      "120/120 - 23s - 189ms/step - accuracy: 0.0511 - loss: 6.7481e-04 - val_accuracy: 0.1939 - val_loss: 0.0020 - learning_rate: 6.2500e-05\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00059\n",
      "120/120 - 23s - 193ms/step - accuracy: 0.0485 - loss: 6.9250e-04 - val_accuracy: 0.1887 - val_loss: 9.4917e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 182ms/step - accuracy: 0.0511 - loss: 7.3162e-04 - val_accuracy: 0.1929 - val_loss: 9.0764e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0584 - loss: 6.0355e-04 - val_accuracy: 0.1845 - val_loss: 0.0012 - learning_rate: 3.1250e-05\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 180ms/step - accuracy: 0.0459 - loss: 5.3656e-04 - val_accuracy: 0.1876 - val_loss: 0.0015 - learning_rate: 3.1250e-05\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0474 - loss: 0.0014 - val_accuracy: 0.2107 - val_loss: 0.0022 - learning_rate: 1.5625e-05\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 186ms/step - accuracy: 0.0514 - loss: 8.0414e-04 - val_accuracy: 0.2034 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00059\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0516 - loss: 6.1979e-04 - val_accuracy: 0.2034 - val_loss: 0.0010 - learning_rate: 1.5625e-05\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "\n",
      "Fold 1 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[477   0]\n",
      " [  0 477]]\n",
      "TN=477, FP=0, FN=0, TP=477\n",
      "\n",
      "Fold 1 Metrics (threshold=0.5):\n",
      "Accuracy    : 1.0000\n",
      "Precision   : 1.0000  (class 1: Professional)\n",
      "Sensitivity : 1.0000     (Recall for class 1)\n",
      "Specificity : 1.0000 (for class 0: Amateur)\n",
      "F1-score    : 1.0000\n",
      "\n",
      "==========================================================================================\n",
      "Fold 2 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(-0.0007, 1.0084) | Train per-electrode std range: [1.000, 1.000]\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_1\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
       "│                                   │                              │                   │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_1\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_1\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
       "│                                   │                              │                   │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_11[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_10[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_12[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_13[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_1\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_14[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_15[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 2...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.33744, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 245ms/step - accuracy: 0.0000e+00 - loss: 0.3598 - val_accuracy: 0.0000e+00 - val_loss: 3.3374 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss did not improve from 3.33744\n",
      "120/120 - 21s - 179ms/step - accuracy: 0.0076 - loss: 0.1020 - val_accuracy: 0.0136 - val_loss: 6.2402 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss did not improve from 3.33744\n",
      "120/120 - 22s - 179ms/step - accuracy: 0.0081 - loss: 0.0605 - val_accuracy: 0.3816 - val_loss: 6.1944 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 3.33744 to 3.04954, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 183ms/step - accuracy: 0.0173 - loss: 0.0386 - val_accuracy: 0.4004 - val_loss: 3.0495 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 3.04954 to 1.26511, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0139 - loss: 0.0370 - val_accuracy: 0.4581 - val_loss: 1.2651 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 1.26511 to 0.08618, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 180ms/step - accuracy: 0.0142 - loss: 0.0333 - val_accuracy: 0.1132 - val_loss: 0.0862 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.08618\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0165 - loss: 0.0279 - val_accuracy: 0.4738 - val_loss: 0.3032 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.08618\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0241 - loss: 0.0181 - val_accuracy: 0.4057 - val_loss: 0.0989 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.08618 to 0.04344, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 176ms/step - accuracy: 0.0270 - loss: 0.0191 - val_accuracy: 0.1310 - val_loss: 0.0434 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.04344\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0288 - loss: 0.0214 - val_accuracy: 0.4958 - val_loss: 0.9503 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.04344 to 0.00770, saving model to best_fold_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0218 - loss: 0.0182 - val_accuracy: 0.3040 - val_loss: 0.0077 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0228 - loss: 0.0227 - val_accuracy: 0.2075 - val_loss: 0.0278 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0322 - loss: 0.0181 - val_accuracy: 0.1646 - val_loss: 0.0389 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0273 - loss: 0.0324 - val_accuracy: 0.3239 - val_loss: 0.0299 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0210 - loss: 0.0189 - val_accuracy: 0.3029 - val_loss: 0.0131 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0246 - loss: 0.0096 - val_accuracy: 0.2086 - val_loss: 0.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0338 - loss: 0.0070 - val_accuracy: 0.0660 - val_loss: 0.0247 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0328 - loss: 0.0031 - val_accuracy: 0.1614 - val_loss: 0.0126 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0377 - loss: 0.0019 - val_accuracy: 0.1866 - val_loss: 0.0123 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0461 - loss: 0.0012 - val_accuracy: 0.1971 - val_loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0459 - loss: 0.0028 - val_accuracy: 0.1614 - val_loss: 0.0107 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0461 - loss: 0.0021 - val_accuracy: 0.1310 - val_loss: 0.0135 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0482 - loss: 0.0015 - val_accuracy: 0.1562 - val_loss: 0.0126 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0461 - loss: 0.0017 - val_accuracy: 0.1530 - val_loss: 0.0119 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0532 - loss: 0.0021 - val_accuracy: 0.1394 - val_loss: 0.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00770\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0495 - loss: 0.0012 - val_accuracy: 0.1153 - val_loss: 0.0118 - learning_rate: 1.2500e-04\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "\n",
      "Fold 2 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[476   1]\n",
      " [  1 476]]\n",
      "TN=476, FP=1, FN=1, TP=476\n",
      "\n",
      "Fold 2 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9979\n",
      "Precision   : 0.9979  (class 1: Professional)\n",
      "Sensitivity : 0.9979     (Recall for class 1)\n",
      "Specificity : 0.9979 (for class 0: Amateur)\n",
      "F1-score    : 0.9979\n",
      "\n",
      "==========================================================================================\n",
      "Fold 3 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(0.0003, 0.9593) | Train per-electrode std range: [1.000, 1.000]\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_2\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_19            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_20            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_4               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_21            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_5               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_22            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_2\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_23            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_16[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_2\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_17[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_19            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_13 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_19[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_12 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_18[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_20            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_4               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_20[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_21            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_14 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_21[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_5               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_2[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_22            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_2\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_22[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_23            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_23[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 3...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 2.46172, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 238ms/step - accuracy: 2.6205e-04 - loss: 0.3079 - val_accuracy: 0.0000e+00 - val_loss: 2.4617 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss did not improve from 2.46172\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0021 - loss: 0.0843 - val_accuracy: 0.0000e+00 - val_loss: 3.1566 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss did not improve from 2.46172\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0024 - loss: 0.0624 - val_accuracy: 0.1300 - val_loss: 4.2462 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 2.46172 to 0.18633, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0039 - loss: 0.0494 - val_accuracy: 0.0000e+00 - val_loss: 0.1863 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.18633 to 0.09460, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 0.0123 - loss: 0.0386 - val_accuracy: 0.0136 - val_loss: 0.0946 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.09460 to 0.09101, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 176ms/step - accuracy: 0.0105 - loss: 0.0369 - val_accuracy: 0.0094 - val_loss: 0.0910 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.09101 to 0.03984, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 183ms/step - accuracy: 0.0107 - loss: 0.0315 - val_accuracy: 0.0021 - val_loss: 0.0398 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.03984 to 0.02817, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0121 - loss: 0.0335 - val_accuracy: 0.0713 - val_loss: 0.0282 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.02817 to 0.02606, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0086 - loss: 0.0244 - val_accuracy: 0.0482 - val_loss: 0.0261 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.02606\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0136 - loss: 0.0250 - val_accuracy: 0.0000e+00 - val_loss: 0.2675 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.02606\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0223 - loss: 0.0235 - val_accuracy: 0.1562 - val_loss: 0.1383 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.02606\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0194 - loss: 0.0228 - val_accuracy: 0.0273 - val_loss: 0.0862 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.02606 to 0.01282, saving model to best_fold_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - accuracy: 0.0286 - loss: 0.0208 - val_accuracy: 0.1069 - val_loss: 0.0128 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0212 - loss: 0.0203 - val_accuracy: 0.0136 - val_loss: 0.0571 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0262 - loss: 0.0181 - val_accuracy: 0.1174 - val_loss: 0.0188 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0307 - loss: 0.0155 - val_accuracy: 0.0964 - val_loss: 0.0352 - learning_rate: 1.0000e-03\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0278 - loss: 0.0179 - val_accuracy: 0.3732 - val_loss: 0.2464 - learning_rate: 1.0000e-03\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0291 - loss: 0.0126 - val_accuracy: 0.1667 - val_loss: 0.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0312 - loss: 0.0101 - val_accuracy: 0.2264 - val_loss: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0367 - loss: 0.0083 - val_accuracy: 0.1625 - val_loss: 0.0393 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0364 - loss: 0.0058 - val_accuracy: 0.2463 - val_loss: 0.0292 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0417 - loss: 0.0037 - val_accuracy: 0.2463 - val_loss: 0.0257 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0445 - loss: 0.0050 - val_accuracy: 0.1771 - val_loss: 0.0411 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0485 - loss: 0.0031 - val_accuracy: 0.2883 - val_loss: 0.0271 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0597 - loss: 0.0018 - val_accuracy: 0.2505 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0597 - loss: 0.0021 - val_accuracy: 0.2149 - val_loss: 0.0377 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 173ms/step - accuracy: 0.0584 - loss: 0.0017 - val_accuracy: 0.2421 - val_loss: 0.0326 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01282\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0605 - loss: 0.0018 - val_accuracy: 0.2547 - val_loss: 0.0229 - learning_rate: 1.2500e-04\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\n",
      "Fold 3 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[475   2]\n",
      " [  2 475]]\n",
      "TN=475, FP=2, FN=2, TP=475\n",
      "\n",
      "Fold 3 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9958\n",
      "Precision   : 0.9958  (class 1: Professional)\n",
      "Sensitivity : 0.9958     (Recall for class 1)\n",
      "Specificity : 0.9958 (for class 0: Amateur)\n",
      "F1-score    : 0.9958\n",
      "\n",
      "==========================================================================================\n",
      "Fold 4 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(0.0000, 1.0000) | Val(mean,std)=(0.0012, 0.9685) | Train per-electrode std range: [1.000, 1.000]\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_24            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_3\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_25            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_27            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_26            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_28            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_6               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_29            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_7               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_30            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_3\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_24            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_15 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_24[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_3\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_25            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_16 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_25[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_27            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_18 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_27[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_26            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_17 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_26[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_28            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_6               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_28[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_29            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_19 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_29[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_7               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_3[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ dropout_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_30            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_3\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_30[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_31[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 4...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 4.28154, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 28s - 232ms/step - accuracy: 0.0000e+00 - loss: 0.4014 - val_accuracy: 0.0000e+00 - val_loss: 4.2815 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 4.28154 to 2.06641, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 7.8616e-04 - loss: 0.1148 - val_accuracy: 0.0000e+00 - val_loss: 2.0664 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 2.06641 to 0.36945, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0060 - loss: 0.0676 - val_accuracy: 0.0052 - val_loss: 0.3694 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.36945 to 0.09482, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 178ms/step - accuracy: 0.0042 - loss: 0.0539 - val_accuracy: 0.0021 - val_loss: 0.0948 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.09482 to 0.03859, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - accuracy: 0.0081 - loss: 0.0446 - val_accuracy: 0.0210 - val_loss: 0.0386 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.03859 to 0.03569, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0081 - loss: 0.0242 - val_accuracy: 0.2317 - val_loss: 0.0357 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.03569 to 0.01425, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0071 - loss: 0.0248 - val_accuracy: 0.0147 - val_loss: 0.0143 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01425\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0107 - loss: 0.0224 - val_accuracy: 0.2715 - val_loss: 0.0827 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01425\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0121 - loss: 0.0257 - val_accuracy: 0.0168 - val_loss: 0.0197 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01425\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0157 - loss: 0.0193 - val_accuracy: 0.1992 - val_loss: 0.0344 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01425\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0228 - loss: 0.0359 - val_accuracy: 0.0147 - val_loss: 0.0823 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.01425 to 0.00381, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0168 - loss: 0.0131 - val_accuracy: 0.1164 - val_loss: 0.0038 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00381\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0207 - loss: 0.0062 - val_accuracy: 0.3187 - val_loss: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00381\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0249 - loss: 0.0052 - val_accuracy: 0.1006 - val_loss: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00381 to 0.00093, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 179ms/step - accuracy: 0.0244 - loss: 0.0055 - val_accuracy: 0.1792 - val_loss: 9.3462e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00093\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0288 - loss: 0.0035 - val_accuracy: 0.2662 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00093\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0265 - loss: 0.0034 - val_accuracy: 0.0535 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00093\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0280 - loss: 0.0041 - val_accuracy: 0.0535 - val_loss: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00093\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0349 - loss: 0.0030 - val_accuracy: 0.1090 - val_loss: 0.0022 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00093\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0299 - loss: 0.0013 - val_accuracy: 0.0818 - val_loss: 0.0023 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss improved from 0.00093 to 0.00060, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0341 - loss: 0.0027 - val_accuracy: 0.0943 - val_loss: 5.9919e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss improved from 0.00060 to 0.00030, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0383 - loss: 0.0020 - val_accuracy: 0.0975 - val_loss: 3.0252e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00030 to 0.00002, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0359 - loss: 9.4251e-04 - val_accuracy: 0.0440 - val_loss: 2.0365e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00002 to 0.00001, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0404 - loss: 6.4193e-04 - val_accuracy: 0.0849 - val_loss: 9.5047e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss improved from 0.00001 to 0.00001, saving model to best_fold_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 177ms/step - accuracy: 0.0411 - loss: 7.5364e-04 - val_accuracy: 0.0828 - val_loss: 7.5659e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0456 - loss: 8.0393e-04 - val_accuracy: 0.0325 - val_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0480 - loss: 0.0019 - val_accuracy: 0.0860 - val_loss: 0.0029 - learning_rate: 2.5000e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0459 - loss: 0.0014 - val_accuracy: 0.0734 - val_loss: 4.1633e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0498 - loss: 0.0015 - val_accuracy: 0.0922 - val_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0482 - loss: 7.2918e-04 - val_accuracy: 0.0314 - val_loss: 9.0624e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0487 - loss: 3.6042e-04 - val_accuracy: 0.0566 - val_loss: 4.3555e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 176ms/step - accuracy: 0.0485 - loss: 4.7880e-04 - val_accuracy: 0.0514 - val_loss: 3.6867e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0456 - loss: 3.8169e-04 - val_accuracy: 0.0639 - val_loss: 3.4814e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0472 - loss: 3.3876e-04 - val_accuracy: 0.0723 - val_loss: 6.2043e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 178ms/step - accuracy: 0.0498 - loss: 3.2240e-04 - val_accuracy: 0.0577 - val_loss: 7.5289e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00001\n",
      "120/120 - 22s - 181ms/step - accuracy: 0.0545 - loss: 2.0579e-04 - val_accuracy: 0.0514 - val_loss: 5.3779e-05 - learning_rate: 3.1250e-05\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 177ms/step - accuracy: 0.0566 - loss: 2.9504e-04 - val_accuracy: 0.0577 - val_loss: 5.2498e-05 - learning_rate: 3.1250e-05\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0545 - loss: 2.2358e-04 - val_accuracy: 0.0566 - val_loss: 4.5873e-05 - learning_rate: 3.1250e-05\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 174ms/step - accuracy: 0.0529 - loss: 3.8471e-04 - val_accuracy: 0.0472 - val_loss: 6.6183e-05 - learning_rate: 3.1250e-05\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00001\n",
      "120/120 - 21s - 175ms/step - accuracy: 0.0511 - loss: 3.9697e-04 - val_accuracy: 0.0388 - val_loss: 5.6657e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "\n",
      "Fold 4 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[477   0]\n",
      " [  0 477]]\n",
      "TN=477, FP=0, FN=0, TP=477\n",
      "\n",
      "Fold 4 Metrics (threshold=0.5):\n",
      "Accuracy    : 1.0000\n",
      "Precision   : 1.0000  (class 1: Professional)\n",
      "Sensitivity : 1.0000     (Recall for class 1)\n",
      "Specificity : 1.0000 (for class 0: Amateur)\n",
      "F1-score    : 1.0000\n",
      "\n",
      "==========================================================================================\n",
      "Fold 5 — Train/Val split\n",
      "Train idx: (3816,) Val idx: (954,)\n",
      "X_train: (3816, 14, 200, 1) | y_train: (3816,)\n",
      "X_val  : (954, 14, 200, 1) | y_val  : (954,)\n",
      "Per-fold normalization done. train_mean shape: (1, 14, 1, 1) train_std shape: (1, 14, 1, 1)\n",
      "Normalization check — Train(mean,std)=(-0.0000, 1.0000) | Val(mean,std)=(-0.0002, 1.0114) | Train per-electrode std range: [1.000, 1.000]\n",
      "Building model with input_shape: (14, 200, 1)\n",
      "After sepconv1: (None, 14, 200, 32)\n",
      "After SpatialAttention: (None, 14, 200, 32)\n",
      "After depthwise spatial: (None, 1, 200, 64)\n",
      "Residual branch shape: (None, 14, 200, 32)\n",
      "After 1x1 proj to 32: (None, 1, 200, 32)\n",
      "After tiling to electrodes=14: (None, 14, 200, 32)\n",
      "After residual add: (None, 14, 200, 32)\n",
      "After avgpool1: (None, 14, 50, 32)\n",
      "After sepconv2: (None, 14, 50, 64)\n",
      "After avgpool2: (None, 14, 12, 64)\n",
      "Before Transformer, reshaped to: (None, 14, 768)\n",
      "After GAP1D: (None, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_32            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ global_average_pooling2d_4\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_33            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_35            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_34            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ separable_conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
       "│                                   │                              │                   │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_36            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_8               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_37            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ separable_conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_9               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">787,968</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)              │                              │                   │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          \n",
       "│                                   │                              │                   │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ layer_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│                                   │                              │                   │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_38            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ global_average_pooling1d_4\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ batch_normalization_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_39            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_32            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_20 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_32[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling2d_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m2,112\u001b[0m │ global_average_pooling2d_4\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                   │               \u001b[38;5;34m910\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_8 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │                 \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multiply_4 (\u001b[38;5;33mMultiply\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ depthwise_conv2d_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m896\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_33            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_21 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_33[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m2,048\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_35            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                \u001b[38;5;34m37\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_23 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_35[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_34            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ separable_conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_22 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_34[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │                 \u001b[38;5;34m0\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
       "│                                   │                              │                   │ activation_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_36            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m128\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_8               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_36[\u001b[38;5;34m0\u001b[0m][\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ separable_conv2d_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m2,144\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)                 │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_37            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m256\u001b[0m │ separable_conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ activation_24 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_37[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ average_pooling2d_9               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │                 \u001b[38;5;34m0\u001b[0m │ average_pooling2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ reshape_9 (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ multi_head_attention_4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │           \u001b[38;5;34m787,968\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)              │                              │                   │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ multi_head_attention_4[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          \n",
       "│                                   │                              │                   │ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │            \u001b[38;5;34m98,432\u001b[0m │ layer_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │            \u001b[38;5;34m99,072\u001b[0m │ dropout_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│                                   │                              │                   │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ layer_normalization_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │             \u001b[38;5;34m1,536\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ global_average_pooling1d_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ layer_normalization_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_38            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                  │             \u001b[38;5;34m3,072\u001b[0m │ global_average_pooling1d_4\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m98,432\u001b[0m │ batch_normalization_38[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ batch_normalization_39            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ batch_normalization_39[\u001b[38;5;34m0\u001b[0m][\n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ dropout_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,099,897</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,099,897\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097,593</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,097,593\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Setting up callbacks for fold 5...\n",
      "Training with EarlyStopping...\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.91612, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 29s - 242ms/step - accuracy: 0.0000e+00 - loss: 0.3481 - val_accuracy: 0.0000e+00 - val_loss: 3.9161 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 3.91612 to 0.47125, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 187ms/step - accuracy: 7.8616e-04 - loss: 0.1004 - val_accuracy: 0.0000e+00 - val_loss: 0.4713 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.47125 to 0.18598, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - accuracy: 0.0029 - loss: 0.0634 - val_accuracy: 0.0000e+00 - val_loss: 0.1860 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.18598\n",
      "120/120 - 23s - 188ms/step - accuracy: 0.0052 - loss: 0.0395 - val_accuracy: 0.0042 - val_loss: 0.1919 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.18598 to 0.05825, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0105 - loss: 0.0383 - val_accuracy: 0.0283 - val_loss: 0.0583 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.05825 to 0.04294, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 189ms/step - accuracy: 0.0066 - loss: 0.0330 - val_accuracy: 0.0881 - val_loss: 0.0429 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.04294\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0170 - loss: 0.0264 - val_accuracy: 0.1625 - val_loss: 0.0584 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.04294\n",
      "120/120 - 22s - 186ms/step - accuracy: 0.0142 - loss: 0.0358 - val_accuracy: 0.0115 - val_loss: 0.0533 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.04294 to 0.03564, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 186ms/step - accuracy: 0.0176 - loss: 0.0260 - val_accuracy: 0.1017 - val_loss: 0.0356 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.03564\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0225 - loss: 0.0196 - val_accuracy: 0.0524 - val_loss: 0.1465 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.03564 to 0.02931, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - accuracy: 0.0212 - loss: 0.0220 - val_accuracy: 0.0052 - val_loss: 0.0293 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.02931\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0280 - loss: 0.0134 - val_accuracy: 0.3899 - val_loss: 0.1311 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.02931\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0296 - loss: 0.0208 - val_accuracy: 0.2463 - val_loss: 0.0497 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.02931\n",
      "120/120 - 22s - 186ms/step - accuracy: 0.0301 - loss: 0.0155 - val_accuracy: 0.0000e+00 - val_loss: 0.0403 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.02931\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0330 - loss: 0.0068 - val_accuracy: 0.1960 - val_loss: 0.0442 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.02931 to 0.02613, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 186ms/step - accuracy: 0.0474 - loss: 0.0047 - val_accuracy: 0.1310 - val_loss: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.02613 to 0.02197, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 186ms/step - accuracy: 0.0448 - loss: 0.0054 - val_accuracy: 0.2348 - val_loss: 0.0220 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.02197 to 0.01207, saving model to best_fold_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 185ms/step - accuracy: 0.0406 - loss: 0.0031 - val_accuracy: 0.2034 - val_loss: 0.0121 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0367 - loss: 0.0045 - val_accuracy: 0.3491 - val_loss: 0.0423 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0495 - loss: 0.0021 - val_accuracy: 0.1677 - val_loss: 0.0239 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0561 - loss: 0.0038 - val_accuracy: 0.2411 - val_loss: 0.0247 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01207\n",
      "120/120 - 23s - 194ms/step - accuracy: 0.0493 - loss: 0.0017 - val_accuracy: 0.2851 - val_loss: 0.0231 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01207\n",
      "120/120 - 23s - 190ms/step - accuracy: 0.0637 - loss: 0.0025 - val_accuracy: 0.2799 - val_loss: 0.0242 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0545 - loss: 0.0012 - val_accuracy: 0.3050 - val_loss: 0.0256 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0597 - loss: 8.1213e-04 - val_accuracy: 0.2872 - val_loss: 0.0260 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0687 - loss: 0.0013 - val_accuracy: 0.2966 - val_loss: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0603 - loss: 0.0011 - val_accuracy: 0.2945 - val_loss: 0.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0681 - loss: 0.0011 - val_accuracy: 0.2977 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 185ms/step - accuracy: 0.0666 - loss: 8.7114e-04 - val_accuracy: 0.2872 - val_loss: 0.0269 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 184ms/step - accuracy: 0.0721 - loss: 6.1154e-04 - val_accuracy: 0.3040 - val_loss: 0.0269 - learning_rate: 1.2500e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 186ms/step - accuracy: 0.0718 - loss: 5.5526e-04 - val_accuracy: 0.3019 - val_loss: 0.0264 - learning_rate: 6.2500e-05\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 187ms/step - accuracy: 0.0749 - loss: 4.0895e-04 - val_accuracy: 0.2998 - val_loss: 0.0258 - learning_rate: 6.2500e-05\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.01207\n",
      "120/120 - 22s - 186ms/step - accuracy: 0.0797 - loss: 5.3595e-04 - val_accuracy: 0.3008 - val_loss: 0.0247 - learning_rate: 6.2500e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Predicting on validation fold...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n",
      "\n",
      "Fold 5 Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\n",
      "[[475   2]\n",
      " [  2 475]]\n",
      "TN=475, FP=2, FN=2, TP=475\n",
      "\n",
      "Fold 5 Metrics (threshold=0.5):\n",
      "Accuracy    : 0.9958\n",
      "Precision   : 0.9958  (class 1: Professional)\n",
      "Sensitivity : 0.9958     (Recall for class 1)\n",
      "Specificity : 0.9958 (for class 0: Amateur)\n",
      "F1-score    : 0.9958\n",
      "\n",
      "=== Per-Fold Metrics Summary ===\n",
      "Fold 1: Acc=1.0000, Prec=1.0000, Sens=1.0000, Spec=1.0000, F1=1.0000 | TN=477 FP=0 FN=0 TP=477\n",
      "Fold 2: Acc=0.9979, Prec=0.9979, Sens=0.9979, Spec=0.9979, F1=0.9979 | TN=476 FP=1 FN=1 TP=476\n",
      "Fold 3: Acc=0.9958, Prec=0.9958, Sens=0.9958, Spec=0.9958, F1=0.9958 | TN=475 FP=2 FN=2 TP=475\n",
      "Fold 4: Acc=1.0000, Prec=1.0000, Sens=1.0000, Spec=1.0000, F1=1.0000 | TN=477 FP=0 FN=0 TP=477\n",
      "Fold 5: Acc=0.9958, Prec=0.9958, Sens=0.9958, Spec=0.9958, F1=0.9958 | TN=475 FP=2 FN=2 TP=475\n",
      "\n",
      "=== Mean ± Std over 5 folds ===\n",
      "Accuracy    : 0.9979 ± 0.0019\n",
      "Precision   : 0.9979 ± 0.0019\n",
      "Sensitivity : 0.9979 ± 0.0019\n",
      "Specificity : 0.9979 ± 0.0019\n",
      "F1-score    : 0.9979 ± 0.0019\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 3 (training): 5-fold CV with per-fold confusion matrix + metrics =====\n",
    "\n",
    "EPOCHS = 200                                                                   # Upper bound; ES will cut earlier\n",
    "BATCH_SIZE = 32                                                                # Batch size\n",
    "\n",
    "per_fold_metrics = []                                                          # List to store per-fold metric dicts\n",
    "histories = []                                                                 # Store Keras history dicts per fold\n",
    "\n",
    "fold = 0                                                                       # Initialize fold counter\n",
    "for train_idx, val_idx in skf.split(X, y):                                     # Iterate stratified folds\n",
    "    fold += 1                                                                  # Increment fold number\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)                                                       # Visual separator\n",
    "    print(f\"Fold {fold} — Train/Val split\")                                    # Announce fold\n",
    "    print(\"Train idx:\", train_idx.shape, \"Val idx:\", val_idx.shape)            # Show split sizes\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]                                  # Slice EEG training/val data\n",
    "    y_train, y_val = y[train_idx], y[val_idx]                                  # Slice labels training/val\n",
    "\n",
    "    print(\"X_train:\", X_train.shape, \"| y_train:\", y_train.shape)              # Shapes\n",
    "    print(\"X_val  :\", X_val.shape,   \"| y_val  :\", y_val.shape)                # Shapes\n",
    "\n",
    "    # ----- Apply per-fold normalization (uses train-only stats) -----\n",
    "    X_train, X_val = normalize_per_fold(X_train, X_val)                        # Normalize per electrode\n",
    "\n",
    "    # ✅ Quick sanity check: after normalization, TRAIN should be ~mean=0, std=~1\n",
    "    train_global_mean = float(np.mean(X_train))\n",
    "    train_global_std  = float(np.std(X_train))\n",
    "    val_global_mean   = float(np.mean(X_val))\n",
    "    val_global_std    = float(np.std(X_val))\n",
    "    train_per_elec_std = np.std(X_train, axis=(0, 2, 3))  # shape: (14,)\n",
    "\n",
    "    print(\n",
    "        \"Normalization check — \"\n",
    "        f\"Train(mean,std)=({train_global_mean:.4f}, {train_global_std:.4f}) | \"\n",
    "        f\"Val(mean,std)=({val_global_mean:.4f}, {val_global_std:.4f}) | \"\n",
    "        f\"Train per-electrode std range: [{train_per_elec_std.min():.3f}, {train_per_elec_std.max():.3f}]\"\n",
    "    )\n",
    "\n",
    "    model = compile_model()                                                    # Build + compile model\n",
    "    callbacks = make_callbacks(fold)                                           # Create callbacks for this fold\n",
    "\n",
    "    print(\"Training with EarlyStopping...\")                                    # Status\n",
    "    history = model.fit(                                                       # Fit model\n",
    "        X_train, y_train,                                                      # Train data\n",
    "        validation_data=(X_val, y_val),                                        # Validation data\n",
    "        epochs=EPOCHS,                                                         # Max epochs\n",
    "        batch_size=BATCH_SIZE,                                                 # Batch size\n",
    "        callbacks=callbacks,                                                   # Callbacks list\n",
    "        verbose=2                                                              # Per-epoch logs\n",
    "    )\n",
    "\n",
    "    histories.append(history.history)                                          # Store training history dict\n",
    "\n",
    "    print(\"Predicting on validation fold...\")                                  # Status\n",
    "    y_prob = model.predict(X_val, batch_size=BATCH_SIZE).ravel()               # Predict probabilities\n",
    "    y_pred = (y_prob >= 0.5).astype(int)                                       # Threshold at 0.5 to get classes\n",
    "\n",
    "    # ----- Confusion Matrix & Per-fold Metrics -----\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=[0, 1])                        # Confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()                                                # Unpack counts\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Confusion Matrix (rows=true, cols=pred) [0=Amateur, 1=Professional]:\")\n",
    "    print(cm)                                                                  # Print matrix\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")                               # Print counts\n",
    "\n",
    "    acc  = accuracy_score(y_val, y_pred)                                       # Accuracy\n",
    "    prec = precision_score(y_val, y_pred, pos_label=1, zero_division=0)        # Precision (class 1)\n",
    "    sens = recall_score(y_val, y_pred,    pos_label=1, zero_division=0)        # Sensitivity/Recall (class 1)\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0                            # Specificity (class 0)\n",
    "    f1   = f1_score(y_val, y_pred, pos_label=1, zero_division=0)               # F1-score (class 1)\n",
    "\n",
    "    print(\"\\nFold\", fold, \"Metrics (threshold=0.5):\")                          # Header\n",
    "    print(f\"Accuracy    : {acc:.4f}\")                                          # Accuracy\n",
    "    print(f\"Precision   : {prec:.4f}  (class 1: Professional)\")                # Precision\n",
    "    print(f\"Sensitivity : {sens:.4f}     (Recall for class 1)\")                # Sensitivity/Recall\n",
    "    print(f\"Specificity : {spec:.4f} (for class 0: Amateur)\")                  # Specificity\n",
    "    print(f\"F1-score    : {f1:.4f}\")                                           # F1\n",
    "\n",
    "    per_fold_metrics.append({                                                  # Save per-fold metrics\n",
    "        \"fold\": fold, \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
    "        \"accuracy\": float(acc), \"precision\": float(prec),\n",
    "        \"sensitivity\": float(sens), \"specificity\": float(spec), \"f1\": float(f1)\n",
    "    })\n",
    "\n",
    "# ----- Per-fold summary printout -----\n",
    "print(\"\\n=== Per-Fold Metrics Summary ===\")                                     # Header\n",
    "for m in per_fold_metrics:                                                      # Iterate per-fold metrics\n",
    "    print(f\"Fold {m['fold']}: \"\n",
    "          f\"Acc={m['accuracy']:.4f}, \"\n",
    "          f\"Prec={m['precision']:.4f}, \"\n",
    "          f\"Sens={m['sensitivity']:.4f}, \"\n",
    "          f\"Spec={m['specificity']:.4f}, \"\n",
    "          f\"F1={m['f1']:.4f} | \"\n",
    "          f\"TN={m['tn']} FP={m['fp']} FN={m['fn']} TP={m['tp']}\")               # Pretty per-fold line\n",
    "\n",
    "# ----- Optional overall mean ± std across folds -----\n",
    "accs  = [m[\"accuracy\"]    for m in per_fold_metrics]                            # Collect accuracies\n",
    "precs = [m[\"precision\"]   for m in per_fold_metrics]                            # Collect precisions\n",
    "sens  = [m[\"sensitivity\"] for m in per_fold_metrics]                            # Collect sensitivities\n",
    "specs = [m[\"specificity\"] for m in per_fold_metrics]                            # Collect specificities\n",
    "f1s   = [m[\"f1\"]          for m in per_fold_metrics]                            # Collect F1 scores\n",
    "\n",
    "print(\"\\n=== Mean ± Std over 5 folds ===\")                                      # Header\n",
    "print(f\"Accuracy    : {np.mean(accs):.4f} ± {np.std(accs):.4f}\")                # Mean±Std accuracy\n",
    "print(f\"Precision   : {np.mean(precs):.4f} ± {np.std(precs):.4f}\")              # Mean±Std precision\n",
    "print(f\"Sensitivity : {np.mean(sens):.4f} ± {np.std(sens):.4f}\")                # Mean±Std sensitivity\n",
    "print(f\"Specificity : {np.mean(specs):.4f} ± {np.std(specs):.4f}\")              # Mean±Std specificity\n",
    "print(f\"F1-score    : {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")                  # Mean±Std F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abc00d-73b3-4d50-b24b-97115e3678cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
